Парадигмы программирования - совокупность идей и понятий, определяющих стиль написания компьютерных программ
    - Императивная - программа похожа на список приказов - последовательность команд, которые должен выполнить процессор. 
    - Декларативная - программа описывает ожидаемый результат, а не способ его получения (HTML, SQL)

    Императивное программирование. Особенности:
        - инструкции выполняются последовательно
        - данные, получаемые при выполнении предыдущих инструкций, могут читаться из памяти последующими инструкциями
        - данные, полученные при выполнении инструкции могут записыватсья в память
        - использование переменных, оператора присваивания, составных выражений, подпрограмм


Подпрограмма - поименованная или иным образом идентифицированная часть компьютерной программы, содержащая описание определённого набора действий. 
    Подпрограмма может быть многократно вызвана из разных частей программы.

Сопрограмма (корутина, Coroutine) - это потоки исполнения кода, которые организуются поверх аппаратных (системных) потоков.
    Поток исполнения кода - это последовательность операций, которые выполняются друг за другом. 
    В нужные моменты эта последовательность может быть приостановлена, и вместо нее может начать выполняться часть другой последовательности операций.
    
    Системные потоки состоят из инструкций процессора, и на одном ядре процессора могут по очереди работать несколько системных потоков.
    Сопрограммы работают на более высоком уровне - несколько сопрограмм могут по очереди выполнять свой код на одном системном потоке. 
    (В зависимости от реализации, сопрограмма может быть не привязана к конкретному системному потоку, а например выполнять свой код на пуле потоков).

    В отличие от системных потоков, которые переключаются системой в произвольные моменты времени (вытесняющая многозадачность), 
    сопрограммы переключаются вручную, в местах, указанных программистом (кооперативная многозадачность) - сопрограммы умеют задерживать 
    свое выполнение для того, чтобы дождаться результата от другой сопрограммы. 

    yield; - приостановка текущей сопрограммы. Пример в python сопрограммы - генераторы - сопрограммы, которые генерируют последовательности 
    однотипных объектов, например, последовательности чисел.

    Один из основных сценариев применения сопрограмм - это асинхронные операции, такие как ввод-вывод и анимации в UI. 
    После начала асинхронной операции, сопрограмма может сделать yield и продолжиться уже после завершения этой операции. 
    При этом системный поток, на котором она выполнялась, не засыпает вместе с сопрограммой, а остается свободен для других сопрограмм.

    Горутина VS Сопрограмма (корутина)
        - в горутинах нет возможности задать определенный пул потоков, в сопрограммах - можно
        - в горутинах нет возможности определять точки заморозки в функциях. Рантайм Го сам решает, где нужно передать выполнение от одной горутины 
            к другой (в частности, это места IO, а также блокировки на примитивах синхронизации)
        - переключение между двумя Горутинами — супер дешевое, O(1), то есть, не зависит от количества созданных горутин в системе. Всё, что нужно 
            сделать для переключения — это поменять 3 регистра — Program counter, Stack Pointer и DX.

Стек вызовов –  LIFO-стек, хранящий информацию для возврата управления из подпрограмм (процедур, функций) в программу.
    Стек - просто линейный блок памяти, содержащий данные или ссылки на них. Рабочая среда использует так называемый указатель стека, чтобы отслеживать 
    местонахождеине вершины стека при исполнении инструкций. При вызове подпрограммы или возникновении прерывания, в стек заносится адрес возврата — 
    адрес в памяти следующей инструкции приостановленной программы и управление передается подпрограмме или подпрограмме-обработчику. При возврате из
    подпрограммы или обработчика прерывания, адрес возврата снимается со стека и управление передается на следующую инструкцию приостановленной (под-)программы. 

Счетчик команд - регистр процессора, который указывает, какую команду нужно выполнять следующей



Общее
1 как в golang реализовано Наследование, Инкапсуляция, Полиморфизм
    
    Наследование, Инкапсуляция, Полиморфизм - понятия, относящиеся к ООП.
    Go является объектно-ориентированным языком. 
        ООП это методология программирования, основанная на представлении программы в виде совокупности объектов, 
        каждый из которых является экземпляром определённого класса, а классы образуют иерархию наследования
        
        Основные принципы структурирования в случае ООП:
            -инкапсуляция - свойство системы, позволяющее объединить данные и методы, работающие с ними
            Go инкапсулирует данные и методы на уровне пакета. Имена, начинающиеся со строчной буквы, видны только внутри этого пакета.

            -наследование - свойство системы, позволяющее описать новый класс на основе уже существующего с 
            частично или полностью заимствованной функциональностью. 
            В Go наследования нет, Go предпочитает композицию (структур). Go не имеет никакой иерархии типов. 
            Это позволяет вам делиться деталями реализации через композицию.

            -полиморфизм (подтипов) - свойство системы, позволяющее использовать объекты с одинаковым 
            интерфейсом без информации о типе и внутренней структуре объекта. Другой вид полиморфизма — параметрический — в 
            ООП называют обобщённым программированием. Истинный полиморфизм - параметрический (generics = параметрические типы). 
            В go полиморфизм - ad-hoc ("по месту") полиморфизм.
            Полиморфизм в Go - способность обрабатывать объекты разных типов одинаково, если они придерживаются одного 
            и того же интерфейса. Интерфейсы Go предоставляют эту возможность очень прямым и интуитивно понятным способом. 
            Параметрический полиформизм, когда в функция может обработать переменные разных типов, можно реализовать только 
            кодогенерацией, но применение кодогенерации приводит к "тугости" программы.

            - абстракция данных - Абстрагирование означает выделение значимой информации и исключение из рассмотрения незначимой. 
            В ООП рассматривают лишь абстракцию данных, подразумевая набор наиболее значимых характеристик объекта, 
            доступных остальной программе.

        Структуры Go содержат только состояние и никакого поведения.
        Методы - это функции, которые работают с определенными типами.
        Интерфейсы - это типы, которые объявляют наборы методов.
        Объекты - это языковые конструкции, которые имеют состояние и поведение, которые воздействуют
        на состояние и выборочно предоставляют его другим частям программы.

2 fan-out паттерн
    Fan-in, Fan-Out - это шаблоны обмена сообщениями, используемый для распределения работы между работниками.
        Fan-in - способ схождения данных в один поток данных из нескольких потоков 
        Fan-out - способ разделения данных из одного потока данных в несколько потоков или конвейеров.

            // Создадим источник данных - возвращает канал, в который записывается data бесконечно
                func generate(data string) <-chan string{
                    channel := make(chan string)

                    go func() {
                        for {
                            channel <- data
                            time.Sleep(time.Duration(100*time.Millisecond))
                        }
                    }()
                    return channel
                }
            
            // Fan-in - полезен, когда нужно объединить данные из несокльких каналов
                func fanin(){
                    c1:= generate("Hello")          // создаем 2 генератора
                    c2:= generate("There")          

                    fanin := make(chan string)      // канал который будет сходящимся каналом, будет принимать данные от c1 и c2 .
                    go func(){
                        for{
                            select {                // по мере поступления данных в c1 и c2 считываем и объединяем в fanin
                            case str1 := <-c1: fanin <- str1
                            case str2 := <-c2: fanin <- str2
                            }

                        }
                    }()

                    go func(){
                        for {
                        fmt.Println(<-fanin)
                        }
                    }()

                }

            // Fan-out: Для функции разветвления нам нужен набор приемников, в которых наша функция-генератор будет отправлять
            // сообщения для обработки

                func generate(data string) <- chan string{
                    channel := make(chan string)
                    go func(){
                        for{
                            channel <- data
                            time.Sleep(1000)
                        }
                    }()

                    return channel
                }

                // У Processor есть список рабочих, которые будут использоваться в качестве 
                // фоновых процессов для обработки данных, поступающих из функции генератора (источник данных). 
                type Processor  struct{
                    jobChannel chan string
                    done chan *Worker
                    workers []*Worker
                }
                type Worker struct{
                    name string
                }

                func (w * Worker) processJob(data string, done chan *Worker){
                    // Use the data and process the job
                    go func(){
                        fmt.Println("Working on data ", data, w.name)
                        time.Sleep(3000)
                        done <- w
                    }()

                }

                func GetProcessor() * Processor{
                    p := &Processor{
                        jobChannel: make(chan string),
                        workers: make([]*Worker,5),
                        done: make( chan *Worker),
                    }
                    for i := 0; i < 5; i++ {
                        w := &Worker{name : fmt.Sprintf("<Worker - %d>", i)}
                        p.workers[i] = w
                    }
                    p.startProcess()
                    return p
                }

                func (p *Processor) startProcess(){
                    go func(){
                        for{
                            select {
                            case w := <- p.done:
                                p.workers = append(p.workers, w)
                            default :
                                if len(p.workers) > 0 {
                                    w := p.workers[0]
                                    p.workers = p.workers[1:]
                                    w.processJob( <- p.jobChannel,p.done)
                                }
                        }
                    }()
                }

                // получаем сообщение от генератора и направляем его в jobChannel канал в экземпляре Processor
                func (p *Processor) postJob(jobs <-chan string){
                    p.jobChannel <- <-jobs
                }

                func main() {
                    source := generate("data string")
                    process := GetProcessor()

                    for i := 0; i < 12; i++ {
                        process.postJob(source)
                    }
                }
            // В реальном сценарии мы должны создать рабочий пул на основе очереди приоритетов, чтобы работа распределялась 
            // равномерно и процессор не блокировался. Также эта установка не учитывает backpressure. Строка 
                      w.processJob( <- p.jobChannel,p.done)
            // может заблокироваться, если нет работы. В таких случаях не забудьте добавить обработку backpressure. 

            //Еще пример Fan-out
                // Функция `Split` преобразует один канал в список каналов с помощью goroutine для копирования 
                //полученных значений по каналам в списке в циклическом порядке.
               
                // Разделить канал на n каналов, которые получают сообщения в циклическом порядке.
                func Split(ch <-chan int, n int) []<-chan int {
                    // Создаем пул из n каналов
                    cs := make([]chan int)
                    for i := 0; i < n; i++ {
                        cs = append(cs, make(chan int))
                    }

                    // Распределяет работу в круговом порядке среди указанного числа каналов, 
                    // пока основной канал не будет закрыт. При закрытии основного канала закрывает 
                    // все каналы и возвращается.
                    toChannels := func(ch <-chan int, cs []chan<- int) {

                        // Закрываем каждый канал, 
                        // когда выполнение заканчивается.
                        defer func(cs []chan<- int) {
                            for _, c := range cs {
                                close(c)
                            }
                        }(cs)

                        // Направляем сообщения из основного канала ch в каналы из пула cs
                        for {
                            for _, c := range cs {
                                select {
                                case val, ok := <-ch:
                                    if !ok {
                                        return
                                    }

                                    c <- val
                                }
                            }
                        }
                    }

                    go toChannels(ch, cs)

                    return cs
                }


            Пул воркеров:

                    /*
                    3. Дана последовательность чисел: 2,4,6,8,10.
                    Найти сумму их квадратов(2*2+3*3+4*4….) с использованием конкурентных вычислений.

                    Реализация: пул воркеров с учетом Rate-лимитов (гибкая настройка ограничений ресурсов)
                    Синхронизация через wg.WaitGroup, wg.Lock/Unlock
                    */

                    func Task3() {
                        const (
                            arrSize    = 5
                            goroutines = 3
                            quotaLimit = 2
                        )

                        array := [arrSize]int{2, 4, 6, 8, 10}
                        wg := &sync.WaitGroup{}
                        mutex := &sync.Mutex{}
                        workerInput := make(chan int, quotaLimit)
                        var sum int

                        // создаем горутины
                        for i := 0; i < goroutines; i++ {
                            go worker3(i, workerInput, wg, mutex, &sum)
                        }

                        // воркеры сами разберутся - задача идет в канал.
                        // рандомная горутина принимает к работе
                        for _, num := range array {
                            // создаем счетчик задач для решения, чтобы дождаться корректного завершения горутин
                            wg.Add(1)
                            workerInput <- num
                        }

                        // обязательно закрыть канал (пул воркеров) - иначе не дождемся окончания
                        // работы воркеров. Это может привести к дедлоку или утечки памяти
                        close(workerInput)

                        // ожидание завершения работы горутин
                        wg.Wait()
                        fmt.Printf("Task3. Sum of squares = %d\n\n", sum)
                    }

                    func worker3(workerName int, in <-chan int, wg *sync.WaitGroup, mutex *sync.Mutex, sum *int) {
                        /*
                            используя пул воркеров, бесконечный цикл обязателен:
                                -поскольку горутин создано 3, а задач в пуле воркеров - 5. Тогда
                                3 горутины в сумме считают из канала 3 раза, а 2 задачи останутся необработанными
                                Если завершить работу программы, оставив заполненным буфер канала (но не переполненным!),
                                то паники (deadlock) - не произойдет (!),
                                но задачи так и останутся не выполнеными. Вне зависимости от количества созданных
                                горутин, в цикле горутина получит из канала новую задачу и выполнит ее

                                но, используя бесконечный цикл, необходимо прервать его по завершению работы горутины
                                чтобы не оставлять ее в памяти
                        */
                        for {
                            // num - значение из канала, а more - bool переменная, равная false, если канал закрыт
                            // горутина завершается, если канал in закрыт
                            num, more := <-in
                            if more {
                                // выполнение работы из пула
                                mult := num * num

                                // Чтобы избежать состояния гонки - блокируем горутины
                                mutex.Lock()
                                *sum += mult

                                // т.к. выводим значение с общим ресурсом *sum, то Println() - внутри Lock()
                                fmt.Printf("Goroutine #%d: sqr(%d) = %d, sum = %d \n", workerName, num, mult, *sum)
                                mutex.Unlock()

                                /*
                                    уменьшаем счетчик задач для решения.
                                    defer - использовать обязательно (!), т.к. если оставить wg.Done() без defer,
                                    то после выполнения всех задач сразу выполнится wg.Wait(), который не станет ждать завершения горутин,
                                    т.к. счетчик выполненных задач станет равным нулю. Будет выведен результат. А сообщение о завершении
                                    горутин - нет.
                                    т.е. горутины не успеют завершиться до окончания работы программы. Завершиться - выполнить ветку else с
                                    явным возвратом return (и выводом на экран уведомления о завершении работы)
                                */
                                defer wg.Done()
                                runtime.Gosched()
                            } else {
                                fmt.Printf("Task3. All jobs is done. (Worker #%d) \n", workerName)
                                return
                            }
                        }
                    }


3 Инвертирование зависимости
    Принцип инверсии зависимостей (англ. dependency inversion principle, DIP) — важный принцип ООП, 
    используемый для уменьшения связанности в компьютерных программах. Входит в пятёрку принципов SOLID.
        SOLID (базовые принципы: "анти-спагетти-код"):
          S - принцип единственной ответственности (код нужно делить на части, чтобы такая часть отвечала за один круг обязанностей
              в go - стуктурирование функций, типов и методов в пакеты)  

          O - принцип открытости/закрытости (Програмные объекты должны быть открыты для расширения и закрыты для модификации.
              в go - расширяем сущности с помощью встраивания одного типа структуры в другой, перекрывать методы встраиваемого типа. Т.е 
              типы в Go открыты для расширения и закрыты для модификации.)

          L - принцип подстановки Барбары Лисков (два типа являются взаимозаменяемыми, если они проявляют такое поведение, при котором вызывающий не может 
               определить разницу. В go - выражать зависимости между вашими пакетами в терминах интерфейсов, а не конкретных типов)

          I - принцип разделения интерфейсов (Интерфейсы не должны быть большими, можно принимать их на вход и никогда не возвращать, 
                Важное эмпирическое правило для Go, принимать интерфейсы, а возвращать структуры.)

          D - принцип инверсии зависимостей (Разделение слоев логики с помощью интерфейсов, 
                В Go ваш граф импортов должен быть ацикличным)
    
    Инверсия зависимостей:
        Модули верхних уровней не должны зависеть от модулей нижних уровней. Оба типа модулей должны зависеть от абстракций.
        Абстракции не должны зависеть от деталей. Детали должны зависеть от абстракций.


Алгоритмы
4 Алгоритмы достижения консенсуса (https://habr.com/ru/company/distributedlab/blog/419185/)
    Алгоритмом достижения консенсуса — называется процесс достижения согласия по поводу значения определенного набора данных
    в распределенных системах. Консенсусные алгоритмы должны быть отказоустойчивыми поэтому обычно предполагается, что должны 
    ответить как минимум 51% узлов сети.

    Поэтому задача достижения консенсуса – задача получения согласованного значения группой участников в ситуации, когда возможны отказы
    отдельных участников, предоставление ими некорректной информации, искажения переданных значений средой передачи данных. 

    Два самых известных алгортима консенсуса для криптовалют являются ProofOfWork и ProofOfStake. Механизмы доказательства 
    о проделанной работе в них отличается достаточно сильно.
        
    Требования к протоколам достижения консенсуса
        -Отсутствие центральной доверенной стороны
        -Честные участники не знают, какие узлы контролируются злоумышленниками. 
        -Сеть заведомо ненадежная
        -Протоколы должны быть полностью формальными (не зависят от человека)
        -Существуют определенные допущения, при которых протокол гарантирует корректную работу

    Proof of work - В PoW выполняется дополнительный объем работы, который сейчас заключается в поиске прообраза хеш-функции.
    Фактически здесь происходит искусственное замедление сети для обеспечения безопасности. Чтобы осуществить злонамеренное
    действие, злоумышленнику придется выполнить необходимый объем работы. Это требует колоссальных затрат энергии и делает 
    реализацию атак не очень эффективной. За счет такого подхода обеспечивается надежность в работе сети.

    Proof of Stake - Идея состоит в использовании “Доли” владения криптовалюты в качестве ресурса определяющего какая нода 
    получит право добычи следующего блока вместо вычислительных операций создатель блока демонстрирует, что он владеет долей 
    в системе ввиде криптовалюты на его кошельке.

    Кроме того, есть алгоритмы Paxos, Raft
    Raft: 
        Сам алгоритм состоит из двух фаз: выбора лидера и непосредственной репликации. Если не вдваться в подробности, 
        то на первой фазе реплики обмениваются сообщениями, чтобы выбрать узел, который будет принимать команды от пользователя. 
        На второй фазе выбранный узел заполняет лог командами и рассылает команды остальным репликам.



Криптографическая хеш-функция - это математический алгоритм, который отображает данные произвольного размера в битовый массив фиксированного размера.
    Результат, производимый хеш-функцией, называется «хеш-суммой» или же просто «хешем», а входные данные часто называют «сообщением».

    Для идеальной хеш-функции выполняются следующие условия:

    а) хеш-функция является детерминированной, то есть одно и то же сообщение приводит к одному и тому же хеш-значению
    b) значение хеш-функции быстро вычисляется для любого сообщения
    c) невозможно найти сообщение, которое дает заданное хеш-значение
    d) невозможно найти два разных сообщения с одинаковым хеш-значением
    e) небольшое изменение в сообщении изменяет хеш настолько сильно, что новое и старое значения кажутся некоррелирующими

    Коллизии хеш-функций 
        Стоит отметить, что коллизии всегда будут существовать для любой хеш-функции по той причине, что возможные входы бесконечны, 
        а количество выходов конечно. Хеш-функция считается устойчивой к коллизиям, когда вероятность обнаружения коллизии настолько мала,
        что для этого потребуются миллионы лет вычислений.
        Несмотря на то, что хеш-функций без коллизий не существует, некоторые из них достаточно надежны и считаются устойчивыми к коллизиям.




Структуры данных
5 Что такое массивы
    Массив - набор данных одного типа. Массивы имеют явно заданную длину.
    Массивы выделяют память во время инициализации.
    Массивы разной длины имеют разные типы (Например, [1]int и [2]int - разные типы)

    массивы копируются во время присваивания к новым переменным или при передаче в функции. 
    В Go нет такой вещи, как передача по ссылке, вместо этого все передается по значению. Если вы хотите передать 
    лишь «ссылку» на массив, используйте указатели.

    Массив хранится в памяти в виде последовательности из n блоков определенного типа.
    Массив имеет длину len() и емкость cap(), которые совпадают

    Можно изменить элемент массива. 
    a := [...]int{1, 2, 3, 4, 5, 6, 7, 8}
	a[3] = 5

    Но использовать функцию append - нельзя (только к слайсам, функция возвращает слайс)
    Массив нельзя сравнивать с nil, а слайсы - можно
    Массив можно сравнивать с массивом, а слайсы со слайсами - нельзя


6 Что такое слайсы
    // СРЕЗЫ (СЛАЙСЫ): подмножество массива (Срезы можно рассматривать как расширенную реализацию массивов). 
    Слайс это ссылка на исходные данные (можно изменять, передавая в функции)
    Слайс - это дескриптор сегмента массива. 
    
    Слайс под капотом состоит из: 
        -указателя на базовый массив (на последовательность данных), 
        -длины сегмента (сколько сейчас элементов в срезе) 
        -его емкости (максимальной длины сегмента, общее количество представленных ячеек памяти).

    Из этого следует, что срезы разной длины можно присваивать друг другу. 
    Они имеют один и тот же тип, а указатель, длина и объем могут меняться

    Срез, в отличии от массива, не выделяет память во время инициализации.
    Фактически, срезы инициализируется с нулевым (nil) значением.

    Если при добавлении элемента длина увеличивается на единицу и тем самым превышает заявленный объем, 
    создается новый базовый массив, который имеет другой адрес в памяти (в этом случае текущий объем обычно удваивается).



7 Что такое len и cap
    Встроенные функции len и cap принимают аргументы различных типов и возвращают результат типа int. 
    Реализация гарантирует, что результат всегда вписывается в int.

        Вызов     Тип аргумента    Результат
        len(s)    string type      длина строки в байтах
                    [n]T, *[n]T    длина массива (== n)
                    []T            длина среза
                    map[K]T        длина карты (количество определенных ключей)
                    chan T         количество элементов находящихся в очереди в буфере канала

        cap(s)    [n]T, *[n]T      длина массива (== n)
                    []T            емкость среза
                    chan T         емкость буфера канала

    Длина nil среза, карты или канала равна 0. Емкость nil среза или канала равна 0.
    nil-срез:   var a[]int
    nil-карта:  var a map[int]int
    nil-канал:  var a chan int



8 Что такое map
    MAP (КАРТЫ) - Это структура данных, которая позволяет хранить пары ключ-значение
        мапа - хеш-таблица, отображение, ассоциативный массив. Map позволяет по ключу быстро получить значение

        В качестве ключа может выступать любая сравниваемая структура данных: 
            -все простые скалярные типы (в т.ч. логические),
            -строковые значения сопоставимы и упорядочены лексически побайтно
            -комплексные (если равны мнимая и реальная части - real(u) == real(v) и imag(u) == imag(v)
            -указатели (два указателя равны, если указывают на одну и ту же переменную или оба nil.
                        Два типа указателей идентичны, если они имеют одинаковые базовые типы)
            -каналы (два канала равны, если были созданы одним и тем же вызовом make, или оба равны nil. Два типа каналов идентичны, если они
                     имеют одинаковые типы элементов и в том же направлении)
            -массивы (два массива сравнимы, если сопоставимы значения типа элемента массива. Два массива равны, если равны из соответствующие элементы + равные длины)
            -интерфейсы (два типа интерфейса идентичны, если у них одинаковый набор методов, с одинаковыми именами и одинаковыми типами функций.
                         или если оба имеют значение nil - ведь интерфейс - это кортеж (Тип, Значение), значит тип и значение двух равных интерфейсов должны совпадать)
            -структуры (две структуры сравнимы, если сопоставимы все их поля. Два значения структуры равны, если их соответствующие не-пустые поля равны.
                        Два типа структуры идентичны, если они имеют одинаковую последовательность полей, 
                        и если соответствующие поля имеют одинаковые имена и одинаковые типы, и идентичные теги. 
                        Неэкспортируемые Имена полей из разных пакеты всегда разные)

        Несравниваемые типы:
            срезы (Два типа срезов идентичны, если они имеют одинаковые типы элементов или оба nil, но не могут быть ключом карты!!)
            мапы (Два типа карт идентичны, если у них одинаковые типы ключей и элементов)
            функциии (Два типа функций идентичны, если у них одинаковое количество параметров и возвращаемых результатов, 
                      а также соответствующие типы параметров и результатов идентичны, 
                      и либо обе функции являются вариативными, 
                      либо ни одна из них не является вариативной. 
                      Имена параметров и результатов могут не совпадать для случая вариативных функций)

        Ключи в Мапе лежат В СЛУЧАЙНОМ ПОРЯДКЕ
        Если ключа в Мапе нет - мапа вернет значение по умолчанию (например, для map[string]int вернет 0)   

        Для применения в данной задаче, к хэш-функциям есть следующие требования:
            -Детерминированность — функция должна вернуть одно и то же значение от одного и того же ключа;
            -Равномерность — должны выдавать значения которые можно было каким-либо образом равномерно распределить в некотором множестве;
            -Скорость — вычисляться быстро, т.к. используются часто;

        Одним из полей структуры мапы является
            unsafe.Pointer — указатель на данные любого типа
            это способ разработчиков GO уйти от проблемы джереников (реализовать функционал мапы с различными типами ключей и значений).

        (!) Карта обеспечивает операции поиска, вставки и удаления за O(1) ожидаемое амортизированное время.

        	var m map[string]int
	        fmt.Printf("%#v\n", m)          // map[string]int(nil)
            m["a"] = 1		                // panic: assignment to entry in nil map

            m = make(map[string]int)
            m["a"] = 1
            value, ok := m["b"]
            fmt.Printf("%#v %#v\n", value, ok)	// 0 false

        (!) Типы карт (map) являются ссылочными типами, такими как указатели или срезы (slice), 
            и поэтому значение m выше равно nil; оно не указывает на инициализированную карту
            Это значит, можно определять функции, которые возвращают не *map[T]T, а map[T]T

        (!) Структура как ключ карты (работает).
                type gg struct {
                    g int
                }

                func main() {
                    var aa map[gg]int = make(map[gg]int)
                    aa[gg{g: 1}] = 1
                    aa[gg{g: 2}] = 2

                    fmt.Println(aa, aa[gg{1}])          // map[{1}:1 {2}:2] 1
                }

        (!) Комплексные числа как структура данных
            var f complex64 = 1 + 2i
            var g complex64 = 4 + 3i
            mm := make(map[complex64]int)
            mm[f] = 1
            mm[g] = 2
            fmt.Println("Hello, 世界", mm)

        (!) Объяснение почему же нельзя взять адрес значения кроется процедуре эвакуации данных. 
        Представьте, что мы взяли адрес значения, а потом мапа выросла, выделилась новая память, данные эвакуировались, 
        старые удалились, указатель стал неправильным, поэтому такие операции запрещены.


    Мапы под капотом
        type hmap struct {
            count      int                  // размер карты
            B          uint8                // log_2 of # of buckets (can hold up to loadFactor * 2^B items)
                                            // количество бакетов - представлено в виде логарифма для ускорения вычислений

            buckets    unsafe.Pointer       // array of 2^B Buckets. may be nil if count==0.
            oldbuckets unsafe.Pointer       // previous bucket array of half the size, non-nil only when growing
        }

        Указатели на данные, попадающие в мапу, хранятся частями — в массиве buckets.
        Каждый бакет содержит 8 пар ключ-значение.
        Бакеты не создаются, пока данных в мапе нет. При появлении данных, создается 8 бакетов.

    Получение данных из мапы:
        Ключи и значения мапы хранятся в выделенном участке памяти, последовательно. Для получения адресов 
        ячеек конкретных ключей и значений, удобно использовать хэширующую функцию.

        1 Ищем бакет с ключом. Он выбирается сравнением первых 8 битов от хэша ключа с соответствующим значением в данных бакета. 
            (проходимся по цепочкам бакетов, переходя в следующее, если в этом не нашли)
        2 После нахождения подходящего бакета, получаем значение ключа (!) по указателю.
            (поиск в бакете начинается с быстрого сравнения дополнительного хэша)
        3 Зная адрес первой ячейки памяти, где размещены значения мапы (не ключи), вычисляем адрес ячейки памяти, где хранится значение и получаем его.


    Поиск, если разобраться, устроен не так уж и сложно: проходимся по цепочкам «ведер», переходя в следующее, если в этом не нашли. 
    Поиск в «ведре» начинается с быстрого сравнения дополнительного хэша (вот для чего эти e0...e7 в начале каждого — это «мини» хэш пары 
    для быстрого сравнения). Если не совпало, идем дальше, если совпало, то проверяем тщательнее — определяем где лежит в памяти ключ, подозреваемый 
    как искомый, сравниваем равен ли он тому, что запросили. Если равен, определяем положение значения в памяти и возвращаем.


    (!) Используйте мапы, но знайте и понимайте как они работают! 
    Можно избежать граблей, поняв некоторые тонкости — почему нельзя взять адрес значения, 
    почему все падает при объявлении без инициализации, 
    почему лучше выделить память заранее, если известно количество элементов (избежим эвакуаций) и многое другое.

    Увеличение размера мапы (эвакуация данных):
        Свойство oldbuckets в структуре мапы необходимо во время процесса миграции данных.
        Миграция начинается при принятии решения о слишком большом кол-ве данных в бакетах - когда в бакетах, в среднем более 6.5 элементов,
        происходит увеличение массива бакетов в 2 раза, а старые данные копируются в него маленькими порциями каждые вставку или удаление, 
        чтобы не создавать очень крупные задержки. Поэтому все операции будут чуть медленнее в процессе эвакуации данных (при поиске тоже, 
        нам же приходится искать в двух местах). После успешной эвакуации начинают использоваться новые данные. 

        При этом текущение значение указателя buckets сохраняется в свойство oldbuckets, после чего в свойстве 
        buckets создается новая структура бакетов, где их становится в 2 раза больше от текущего. 
        Данные мапы копируются из oldbuckets в buckets.

        Т.к. бакетов становится в 2 раза больше, кол-во бакетов всегда равно степени числа 2.
        Именно поэтому в структуре мапы есть свойство B — это степерь двойки, которая показывает кол-во бакетов.    

        Во время миграции данных, все операции мапы остаются доступны. Поэтому во многих частях исходного кода есть 
        обращения как к buckets, так и к oldbuckets. После завершения копирования данных, oldbuckets становится равно nil.

        Из-за возможного изменения адреса памяти данных в связи с миграцией, GO не позволяет получить указатель на значение элемента:
        mymap := map[string]string{"1": "1"}
        fmt.Println(&mymap["1"])                     // cannot take the address of mymap["1"]





9 Запись в map из двух горутин
    параллельное чтение мапы не является проблемой. А вот запись хотя бы одной из горутин в мапу - конкурентно небезопасно

    Параллельность VS конкурентность
        Параллельность - возможность выполнять несколько потоков одновременно (работают несколько потоков одновременно)
            Пример - обслуживание нескольких клиентов одновременно в магазине с несколькими кассами
        Конкурентность - возможность передавать управление другому потоку в процессе выполнения (работает только один поток в единицу времени) 
            Пример - очередь в кабинет врача.

    Проблема конкурентного программирования - непредсказуемость этапов выполнения кода и синхронизация доступа к данным

    Многозадачность VS многопоточность
        Многозадачность (multitasking) — свойство операционной системы или среды выполнения обеспечивать 
        возможность параллельной (или псевдопараллельной) обработки нескольких задач.

        Многопоточность (multithreading) — свойство платформы (например, операционной системы, виртуальной
         машины и т. д.) или приложения, состоящее в том, что процесс, порождённый в операционной системе,
         может состоять из нескольких потоков, выполняющихся «параллельно», то есть без предписанного порядка во времени.

    Процессы
        Процесс — экземпляр программы во время выполнения. Это абстракция, реализованная на уровне операционной системы. 
        Процесс был придуман для организации всех данных, необходимых для работы программы. Это просто контейнер, в котором
        находятся ресурсы программы: 
            -адресное пространство, 
            -потоки, 
            -открытые файлы, 
            -дочерние процессы и т.д. 

    Потоки
        Потоки - ветви кода, выполняющиеся «параллельно», то есть без предписанного порядка во времени.
        Это абстракция, реализованная на уровне операционной системы. Поток был придуман для контроля 
        выполнения кода программы. Поток — это просто контейнер, в котором находятся:
            -счётчик команд
            -регистры
            -стек 

        Поток легче, чем процесс, и создание потока стоит дешевле. Потоки используют адресное пространство
        процесса, которому они принадлежат, поэтому потоки внутри одного процесса могут обмениваться 
        данными и взаимодействовать с другими потоками. 

        В любом процессе создаётся уникальный поток выполнения, который называется основным потоком. 
        Он может с помощью операционной системы запускать или порождать другие потоки, которые делят 
        то же адресное пространство родительского процесса (сегмент кода, сегмент данных, а также 
        другие ресурсы операционной системы, такие как открытые файлы и сигналы). С другой стороны, 
        у каждого потока есть свой идентификатор потока, стек, набор регистров и счётчик команд. 
        По сути, поток представляет собой легковесный процесс, в котором переключение между потоками 
        происходит быстрее, а взаимодействие между процессами - легче.


    Отличие процесса от потока
        Процесс рассматривается ОС, как заявка на все виды ресурсов (память, файлы и пр.), 
        кроме одного — процессорного времени. Поток — это заявка на процессорное время. 
        Процесс — это всего лишь способ сгруппировать взаимосвязанные данные и ресурсы, 
        а потоки — это единицы выполнения (unit of execution), которые выполняются на процессоре. 


    Конкурентность VS параллелизм
        Конкурентность - это способность компьютера справляться с множеством задач одновременно, 
        в то время как параллелизм - способность компьютера выполнять несколько задач одновременно.
    
        Конкурентность — это свойство систем (программы, сети, компьютера и т.д.), допускающее одновременное 
        выполнение нескольких вычислительных процессов, которые могут взаимодействовать друг с другом. 
        Вычисления запускаются, проходят и завершаются в пересекающихся промежутках времени; они также 
        могут происходить абсолютно одновременно (параллелизм), но это не обязательно. 

        Процессоры могут иметь одно или несколько ядер. Одно ядро может выполнять только один набор 
        инструкций в единицу времени. Соответственно, одноядерные процессоры не позволяют выполнять 
        множество задач одновременно. 
        
        
        Конкурентность - это возможность разбивать алгоритм или компьютерную программу на отдельные 
        блоки, которые могут выполняться независимо и коммуницировать между собой.

        Конкурентность: 
            Допустим, у нас одноядерная система и надо выполнить несколько задач, но есть 
            ограничение: одномоментно может быть выполнена лишь одна задача. В модели 
            конкурентного выполнения имеет место переключение контекста между задачами: 
            приложение работает с несколькими задачами, но не может выполнять их все 
            вместе, ведь ядро всего одно. Переключение контекста происходит настолько 
            быстро, что создаётся ощущение, что задачи выполняются одновременно.

        
        Многоядерный процессор способен обрабатывать несколько инструкций в единицу времени, 
        по одной инструкции на ядро. Соответственно, многоядерные процессоры умеют выполнять 
        несколько задач одновременно, за счет чего достигается параллелизм. 

        Параллелизм (true параллелизм может быть только в многопроцессорной/многоядерной системе): 
            В случае с одноядерной системой у нас были ограничения по ресурсам. 
            Если мы добавим несколько ядер, ресурсов станет больше и приложение сможет одновременно
            выполнять на разных ядрах множество задач.

        


    Карты небезопасны для одновременного использования: не определено, что происходит, когда вы читаете и записываете
    в них одновременно.  Если вам нужно читать и записывать на карту из параллельно выполняющихся горутин, доступ должен
    быть опосредован каким-то механизмом синхронизации.  Один из распространенных способов защиты карт - это sync.RWMutex.
        var counter = struct{
            sync.RWMutex
            m map[string]int
        }{m: make(map[string]int)}

        counter.RLock()
        n := counter.m["some_key"]
        counter.RUnlock()
        fmt.Println("some_key:", n)

        counter.Lock()
        counter.m["some_key"]++
        counter.Unlock()
   
   
    Критическая секция — это область вашей программы, которая требует 
    эксклюзивного доступа к общему ресурсу. При нахождении в критической 
    секции двух (или более) потоков возникает состояние race(гонки). 
    Так же возможны проблемы взаимной блокировки(deadlock).



10 Как исправить потоковую небезопасность
    Гонка данных (data race) может возникать, когда две или более горутины одновременно обращаются к одной
    и той же области памяти, и хотя бы одна из них выполняет запись. В то время как map имеет собственный 
    механизм защиты от гонки данных, простые структуры их не имеют, что делает их уязвимыми к этой проблеме.

    В контексте Go - использовать примитивы синхронизации.
        1 WaitGroup — это отличный способ дождаться завершения набора одновременных операций.
        2 Mutex является способом защиты critical section(критическая секция) вашей программы.
        3 RWMutex концептуально то же самое, что и Mutex: он защищает доступ к памяти. 
            Тем не менее, RWMutex дает вам немного больше контроля над памятью. 
            Вы можете запросить блокировку для чтения, и в этом случае вам будет 
            предоставлен доступ, если блокировка не удерживается для записи.

            RWMutex оптимизирован для случаев, когда ваша программа имеет дело с множеством читателей и 
            очень небольшим количеством записывателей.

        4 sync.Cond \ Cond - Условная переменная(condition variable) — примитив синхронизации, 
            обеспечивающий блокирование одного или нескольких потоков до момента поступления
            сигнала от другого потока о выполнении некоторого условия или до истечения 
            максимального промежутка времени ожидания.
                for conditionTrue() == false {
                    time.Sleep(1 * time.Millisecond)
                }

        5 sync.Once - Позволяет определить задачу для однократного выполнения за всё время 
        работы программы. Содержит одну-единственную функцию Do, позволяющую передавать 
        другую функцию для однократного применения.
            once.Do(func(){
                    fmt.println("Выполнится один раз. Сколько бы не вызывали once.Do")
                })
        
        6 Каналы - как способ синхронизации горутин. Каналы имеют встроенный механизм синхронизации — операции вставки 
            и извлечения выполняются последовательно. Обеспечив отправку "задач" через канал с единственным получателем, 
            мы "естественным" образом выполним увеличение счетчика последовательно.

        7 Context - позволяет легко передавать значения в области видимости запроса, сигналы отмены и 
            крайние сроки (deadlines) через границы API всем goroutine, участвующим в обработке запроса.
            Его методы безопасны для одновременного использования несколькими goroutine.

            Пакет context в Go полезен при взаимодействиях с API и медленными процессами, особенно в production-grade системах,
            которые занимаются веб-запросами. С его помощью можно уведомить горутины о необходимости завершить свою работу.
        
            Пакет context в go позволяет вам передавать данные в вашу программу в каком-то «контексте». 
            Контекст так же, как и таймаут, дедлайн или канал, сигнализирует прекращение работы и вызывает return. 

        8 Atomic - Пакет atomic позволяет выполнять атомарные операции с данными. 
            Атомарность обеспечивается функциями runtime_procPin / runtime_procUnpin.
            Данные функции обеспечивают то, что между ними планировщик GO не будет выполнять никакую другую горутину. 
            Благодаря этому код между pin и unpin выполняется атомарно.

            c := int32(0)
            for i := 0; i < n; i++ {
                go func(i int) {
                    atomic.AddInt32(&c, 1)
                }(i)
            }



11 - что такое sync.Map и отличие от map ?
    sync.Map - похожа на обычную карту Go, но безопасна для одновременного использования несколькими горутинами без 
    дополнительной блокировки или координации.

    sync.Map оптимизирован для двух распространенных случаев использования:
        - когда значение для данного ключа записывается только один раз, но читается много раз, как в кэшах, которые только растут, 
        - когда несколько горутин читают, добавляют и перезаписывают значения для непересекающихся наборов ключей. 
    В этих двух случаях использование sync.Map может значительно уменьшить блокировку конкурентного доступа по сравнению с
    обычной картой Go в паре с отдельным Mutex или RWMutex. 

    Методы типа данных sync.Map покрывают все случаи использования мапы — вставка, чтение, удаление, итерирование.
        type Map struct {
            mu sync.Mutex

            read atomic.Value           // указатель на структуру readOnly
            dirty map[interface{}]*entry
            misses int
        }

        type readOnly struct {
            m       map[interface{}]*entry
            amended bool 
        }

    read — указатель на структуру readOnly, в данной структуре хранится часть данных sync.Map, используемая для 
    проверки наличия ключа, либо же чтения. Поэтому при доступе к read мьютексы не нужны (параллельное чтение мапы не является проблемой).

    dirty — мапа, в которой хранится другая часть данных, используемая для добавления новых элементов. Поэтому при доступе к 
    dirty задействуется мьютекс mu.

    Чтение
        В первую очередь пытаемся найти данные в read. Если нашли — возвращаем. Это самый эффективный сценарий — возврат данных из read.
        Во вторую очередь смотрим в dirty — под мьютексом mu. Увеличиваем misses — счетчик чтений dirty. Важный момент — если данный счетчик 
        превышает текущее кол-во элементов dirty, то элементы из dirty будут скопированы в read, а счетчик обнулен. Копирование произойдет 
        синхронно сразу после чтения из dirty — в этот момент мьютекс mu активирован.
        Для того, чтобы впустую не смотеть в dirty, в структуре readOnly есть поле amended, которое собственно и говорит нам о существовании непустого dirty.
    
    Запись
        При записи сначала пытаемся считать ключ из read. Если ключ есть в read, то обновляем с помощью atomic.CompareAndSwap. 
        Данный метод позволяет атомарно изменить значение. Если ключа в read не было, делаем аналогичные действия с dirty. 
        Если dirty был не инициализирован, то инициализируем. Таким образом, обновление уже существующего ключа является простым случаем. 
        Сложнейшим случаем является добавление нового ключа, ранее не существовавшего.

    Итерирование
        При итерировании интересным является то, что перед ним все элементы из dirty копируются в read, если dirty содержит какие-либо элементы. 
        Делается это под локом mu. Далее происходит итерирование по read — обычное итерирование по map.

    Таким образом, sync.Map имеет две внутренние мапы (read и dirty) и благодаря этому пытается избежать использования мьютексов при чтении. 
    При работе с sync.Map нам доступны следующие методы:
        Load(key interface{}) (value interface{}, ok bool)  // чтение
        Store(key, value interface{})                       // вставка
        Delete(key interface{})                             // удаление
        Range(f func(key, value interface{}) bool)          // итеирование
        LoadOrStore(key, value interface{}) (actual interface{}, loaded bool)   // установка значения по ключу, если оно еще не установлено

    sync.Map представляет собой довольно сложную структуру, состояющую в общем 
    случае из двух map — для чтения и для записи новых элементов. Данная структура 
    не только приближается к map+sync.RWMutex, но и может выигрывать у нее, в 
    ситуации преобладающего чтения. В ситуации смешанных чтения и записи новых 
    элементов sync.Map будет иметь как read, так и dirty. В этой ситуации она 
    проиграет map+sync.RWMutex из-за чтения из двух внутренних map, а также 
    затрат действия с счетчиком и копирования данных из dirty в read.

    Когда использовать sync.Map:
        Если ваш кейс заключается в длительном конкурентном сохранении данных в мапу, а затем только в чтении из нее, 
        то на этапе чтения sync.Map определенно эффективен.



12 - race conditions что это и как отловить ?
    Состояние гонки — ошибка проектирования многопоточной системы или приложения, при которой работа 
    системы или приложения зависит от того, в каком порядке выполняются части кода.
    
    Состояние гонки — «плавающая» ошибка (гейзенбаг), проявляющаяся в случайные моменты времени
    и «пропадающая» при попытке её локализовать. 

    Детектор гонки интегрирован с цепочкой инструментов go. Когда установлен флаг командной строки -race, компилятор обрабатывает 
    все обращения к памяти с помощью кода, который записывает, когда и как был осуществлен доступ к памяти, в то время как библиотека 
    времени выполнения отслеживает несинхронизированные обращения к общим переменным. При обнаружении такого "грубого" поведения 
    выдается предупреждение.

    Для того чтобы ловить похожие ошибки, в Go есть специальная директива при запуске программы или компиляции race
        go run -race race_1.go



13 пустой интерфейс
    Интерфейс - контракт, состоящий из набора методов, представляющих стандартное поведение для различных типов данных.
    Тип интерфейса, который не указывает никаких методов, называется пустым интерфейсом.
    Пустой интерфейс может содержать значения любого типа, поскольку каждый тип реализует как минимум ноль методов.
    
    Значение интерфейса состоит из конкретного значения и динамического типа: [Value, Type]
    Нулевым значением типа интерфейса является nil, которое представляется как [nil, nil].

    Пустой интерфейс может использоваться для хранения любых данных, и он может быть полезным параметром, поскольку может работать с любым типом.
    Интерфейс - это два компонента: это набор методов и тип.

    Тип interface{} - это интерфейс, не имеющий методов. Все типы реализуют по крайней мере ноль методов, и удовлетворение интерфейса выполняется 
    автоматически, все типы удовлетворяют пустой интерфейс. Следовательно, метод с пустым интерфейсом в качестве аргумента может принимать любой тип.

    Под капотом интерфейсы реализованы как два элемента: указатель на тип и указатель на связанные данные. 
    Для целочисленного значения 3, интерфейс содержит (схематично) (int, 3)

    Значение интерфейса равно nil, только если внутреннее значение и тип не заданы, (nil, nil).  
    var a interface{}
	if a == nil {   // true

    }

    В частности, интерфейс nil всегда будет иметь тип nil.  Если мы сохраняем nil указатель типа *int внутри значения
    интерфейса, внутренний тип будет *int независимо от значения указателя: (*int, nil).  Таким образом, такое значение
    интерфейса будет отличным от nil, даже если указатель внутри равен nil.

      // структура может удовлетворять интерфейсу, если:
        1) структура содержит встроенную(!) анонимную структуру (!!!), которая удовлетворяет данному интерфейсу!!!
        2) структура имеет все методы, которые требует данный интерфейс
    
    // Пустой интерфейс — это интерфейс,
    который может принять в себя вообще любую переменную,
    потому что у него нет никаких требований к реализации 
    (пустому интерфейсу удовлетворяет вообще любой тип)

    функция Printf() стандартной библиотеки не знает ничего про тип,
    который я только что определил. На самом деле функция Printf() принимает в себя пустой интерфейс.
    Поэтому мы туда можем передавать абсолютно любые параметры,  одни за другими, она все из них выведет

    Пустой интерфейс - ничего не означает. Никакой абстракции. Это невидимый плащ над вашим конкретным типом, 
    который прячет от вас конкретику, и не даёт никакого понимания о поведении. Именно поэтому использовать 
    пустые интерфейсы нужно в самых крайних случаях.

    Что будет в переменной myVal если не получится преобразовать тип из пустого интерфейса ( ok == false )
    myVal, ok := emptyInterfaceVal.(int)
    Ответ - Значение по-умолчанию, для int-а это 0


14 приведение типов (утверждение типов, type assertions)
    Интерфейс определяет поведение данных и может использоваться для хранения данных любого типа. 
    В общем смысле Утверждение означает утверждение, в истинность которого вы твердо верите. 

    val, ok := interface.(TYPE)
    
    Утверждение типа используются для проверки того, реализует ли значение, содержащееся в переменной типа интерфейса, 
    желаемый интерфейс или имеет ли он конкретный тип. 

    val, ok := i.(B)
    Если утверждение не выполняется, то первым значением будет default значение для тестируемого типа. 


14.1 Преобразование типа 
    Как следует из названия, это способ преобразования переменной из одного типа данных в другой тип данных.
    T(v)    // преобразует значение v в тип T. 




15 Горутина — это эффективный и легковесный механизм многопоточного выполнения. 
    С помощью семантики горутин программисты добиваются эффективного выполнения параллельных задач. 
    Горутина — это функция, выполняющаяся конкурентно с другими горутинами в том же адресном пространстве.
    Горутину можно рассматривать как легковесную абстракцию на стандартными системными потоками.

    goroutines vs threads
        Процесс - это часть операционной системы, которая отвечает за выполнение приложения. 
        Каждая программа, выполняемая в вашей системе, является процессом, и для запуска 
        кода внутри приложения процесс использует термин, известный как поток.

        Поток - это легкий процесс, или, другими словами, поток - это блок, который выполняет 
        код в рамках программы. Таким образом, каждая программа имеет логику, и за выполнение этой логики отвечает поток.

    Горутины         	                         VS                 Потоки
    
    Горутины управляются средой выполнения go. 	                    Потоки операционной системы управляются ядром ОС.
    
    Горутины не зависят от оборудования. 	                        Потоки зависят от оборудования (ядер ЦП).
    
    У горутин есть простое средство коммуникации,                   У потока нет простого средства коммуникации.
    известное как канал. 	                                        
    
    Благодаря наличию канала горутина                               Из-за отсутствия удобной среды передачи межпотоковая
    может взаимодействовать с другой горутиной                      связь происходит с большой задержкой.
    с малой задержкой. 	
    
    Goroutine не имеет идентификатора, потому что go                У потоков есть собственный уникальный идентификатор, 
    не имеет локального хранилища потоков. 	                        потому что у них есть локальное хранилище потоков.
    
    Горутины дешевле потоков. (2Кб объем стека) 	                Стоимость создания потока выше горутины. (1 МБ)
    
    Горутины планируются совместно. 	                            Потоки запланированы заранее.
    
    У горутин время запуска быстрее, чем у потоков. 	            У потоков более медленное время запуска, чем у горутин.

    Goroutine имеет расширяемые сегментированные стеки. 	        У потоков нет растущих сегментированных стеков. 




16 Планировщик GO
    Цель планировщика (scheduler) в том, чтобы распределять готовые к выполнению горутины (G) по свободным машинам (M).

    Модели распределения пользовательских потоков по потокам ОС:
        N:1 - несколько потоков пользовательского пространства выполняются в одном потоке ОС. 
            +очень быстро переключает контекст
            -не может использовать преимущества многоядерных систем
        1:1 - один пользовательский поток выполнения соответствует одному потоку ОС. 
            +он использует преимущества всех ядер на машине
            -но переключение контекста происходит медленно, потому что оно должно перехватывать через ОС. 

    В Go реализована модель M:N
        +быстрое переключение контекста
        +преимущества многоядерных систем

    В исходном коде (src/pkg/runtime/proc.c) приняты такие термины:
        G (Goroutine) — Горутина
        M (Machine) — Машина        // поток ОС. Это поток выполнения, управляемый ОС
        P (Processor) - Процессор   // не ЦП, а контекст для планирования, в каждом потоке ОС есть один контекст
                                    // процессор имеет очередь горутин, и одну горутину, которая исполняется на
                                    // машине
    
    Количество контекстов P устанавливается при запуске равным значению GOMAXPROCS() (По умолчанию оно равно 1)
    например, на 4-ядерном ПК можно настроить выполнение кода Go в 4 потоках, поэтому
    имеет смысл сделать GOMAXPROCS равным числу ядер.

    С помощью этого GOMAXPROCS мы запрашиваем переход приложения на несколько ядер. И ключевые слова go, добавляющиеся 
    перед исполнением функции, могут исполняться уже отдельно на разных ядрах, увеличивая производительность приложения.

    Перед запуском горутины выстроены в очередь выполнения.
    
    Как только контекст запускает горутину до точки планирования, он извлекает горутину из своей очереди выполнения,
    устанавливает стек и указатель инструкций и начинает выполнение горутины. 

    Чтобы уменьшить конкуренцию за мьютекс (в случае общей очереди на все машины), каждый контекст имеет свою собственную 
    локальную очередь выполнения.

    Планировщик продолжает планирование в этом устойчивом состоянии до тех пор, пока во всех контекстах есть горутины для запуска.
    Контексты нужны для того, чтобы стало возможным передача этих контекстов другим потокам, если запущенный поток по какой-то причине
    должен заблокироваться (например, системный вызов - передача управления ядру ОС - open, read, write, close, wait, exec, fork, exit и kill:
    приложения обычно ограничены своим адресным пространством таким образом, что они не могут получить доступ или модифицировать другие 
    приложения, исполняемые в операционной системе, либо саму операционную систему, и обычно не могут напрямую получать доступ к системным
    ресурсам (жёсткие диски, видеокарта, сетевые устройства и т. д.). )


    Алгоритм выполнения горутины с системным вызовом:
        - горутина отказывается от своего контекста
        - если есть свободная Машина (поток ОС) для запуска всех контекстов, то планировщик прикрепляет горутину к ней
        - когда управление пришло в горутину из системного вызова, горутина должна попытаться получить контекст
        - обычно горутина "ворует" контекст из других машин
        - если горутина не может украсть контекст, то планировщик поместит горутину глобальную очередь выполнения

        Глобальная очередь выполнения - это очередь выполнения, из которой контексты извлекаются, когда заканчиваются горутины в своей 
        локальной очереди выполнения. Контексты также периодически проверяют глобальную очередь выполнения на наличие горутин. 
        В противном случае горутины в глобальной очереди выполнения могут перестать работать из-за голода. 

        Благодаря такой обработке системных вызовов программы Go выполняются с несколькими потоками, даже если GOMAXPROCS равно 1. 
        Среда выполнения использует горутины, которые вызывают системные вызовы, оставляя потоки позади. 


    Что будет, когда в контексте заканчиваются горутины для планирования?
        - контекст может извлекать горутины из глобальной очереди выполнения (если они там есть)
        - иначе контекст пытается украсть около половины очереди выполнения из другого контекста. Это гарантирует, 
            что всегда есть над чем поработать в каждом из контекстов, что, в свою очередь, гарантирует, что все потоки работают 
            с максимальной производительностью.


    Каждая Машина работает в отдельном потоке ОС и способна выполнять только одну Горутину в момент времени. 
     
    -Готовые к исполнению горутины выполняются в порядке очереди
    -Исполнение горутины прерывается только тогда, когда она уже не может выполняться: то есть из-за системного 
        вызова или использования синхронизирующих объектов
    -Как только функция вновь готова к выполнению, она снова попадает в очередь.
    


17 Какие есть системы межпроцессного взаимодействия?

    Операционные системы реального времени, поддерживающие многозадачность, должны использовать такие средства межпроцессного 
    взаимодействия, которые гарантируют синхронизацию без взаимоисключений и с минимальными задержками.

    Межпроцессное взаимодействие (Inter-process communication (IPC)) — это набор методов для обмена данными
    между потоками процессов. Процессы могут быть запущены как на одном и том же компьютере, так и на разных, 
    соединенных сетью. IPC бывают нескольких типов: 
        
        1 каналы (ОС) - средство связи стандартного вывода одного процесса со стандартным вводом другого

        2 сигнал - асинхронное уведомление процесса о каком-либо событии (программное прерывание, которые посылаются процессу, когда случается некоторое событие, 
            например, ошибка адресации)

        3 сокет - сокет является развитием механизма каналов. Сокеты обеспечивают двухстороннюю связь типа точка-точка между двумя процессами. 
            Они являются основными компонентами межсистемной и межпроцессной связи. Каждый сокет представляет собой конечную точку связи, с 
            которой может быть совмещено некоторое имя. Он имеет определенный тип, и один процесс или несколько, связанных с ним процессов.

        4 семафор - примитив синхронизации работы процессов и потоков, в основе которого лежит счётчик, над которым можно производить
                  две атомарные операции: увеличение и уменьшение значения на единицу

        5 разделяемая память - отображение участка (сегмента) памяти, которая будет разделена между более чем одним процессом. 
            Информация отображается непосредственно из сегмента памяти в адресное пространство вызывающего процесса. 
            Сегмент может быть создан одним процессом и впоследствии использован для чтения/записи любым количеством процессов.

        6 очереди сообщений - связный список в адресном пространстве ядра. Сообщения могут посылаться в очередь по порядку и 
            доставаться из очереди несколькими разными путями. Каждая очередь сообщений однозначно определена идентификатором IPC. 
            Очереди сообщений как средство межпроцессной связи позволяют процессам взаимодействовать, обмениваясь данными. 
            Данные передаются между процессами дискретными порциями, называемыми сообщениями.


19 Мьютексы какими бывают? чем отличаются от семафоров?    
    Разница только в том, что мьютекс объекта может захватить одновременно только один поток, 
    а в случае с семафором используется счетчик потоков, и доступ к ресурсу могут получить сразу
    несколько из них. На самом деле мьютекс — это одноместный семафор.


20 как завершить N горутин. Как сделать без контекста?
    с помощью каналов
    Аксиомы канала:
        - Отправка в нулевой канал nil блокирует навсегда.
        - Получение из нулевого канала nil блокируется навсегда.
        - Закрытие нулевого канала nil вызывает panic.
        - Отправка в закрытый канал вызывает panic.
        - Получение из закрытого канала немедленно возвращает нулевое значение типа канала (если буфер пустой).
        - Закрытие уже закрытого канала вызывает panic.





21 Аллокация памяти в горутинах
    Стек горутин изначально весит всего 2 КБ, может автоматически увеличиваться/уменьшаться в соответствии с нашими потребностями.
    Интересно отметить, что при запуске процесса сборки мусора стек будет уменьшен если это необходимо.

    Максимальный размер стека составляет 1 ГБ для 64-битной версии и 250 МБ для 32-битной.
    Непрерывный стек — это стратегия копирования стека в большее пространство, в противоположность сегментированному стеку.

    Текущий механизм разделения стека имеет проблему «горячего разделения» - если стек почти заполнен, вызов заставит выделить 
    новый фрагмент стека. Когда этот вызов возвращается, новый фрагмент стека освобождается. Если один и тот же вызов повторяется 
    в замкнутом цикле, накладные расходы на выделение / освобождение вызывают значительные накладные расходы.
    Работа по выделению / освобождению стека никогда не завершается с разделенными стеками - каждый раз, когда размер стека превышает 
    пороговое значение в любом направлении, требуется дополнительная работа. 

    Используя непрерывные стеки, мы избегаем обеих этих проблем. Стеки увеличиваются до необходимого размера, и с этого момента 
    больше не нужно работать 

    https://habr.com/ru/company/otus/blog/586108/
    https://docs.google.com/document/d/1wAaf1rYoM4S4gtnPh0zOlGzWtrZFQ5suE8qr2sD8uWQ/pub 
    По этой причине Go пришлось увеличить минимальный размер стека в версии 1.2 до 8 КБ, а позже, после реализации непрерывного стека,
    его удалось уменьшить обратно до 2 КБ.



22 Сборщик мусора (GC, garbage collector)
    Сборка мусора - это процесс освобождения места в памяти, которое больше не используется.
    Другими словами, сборщик мусора определяет объекты, находящиеся вне области видимости, на которые нельзя больше 
    ссылаться (недостижимые объекты), и освобождает занимаемую ими память. Этот процесс выполняется конкурентно, не до 
    и не после, а во время работы Go-программы

    Фаза 1. Фаза сканирования: определить, какие вещи в куче достижимы. Сюда входят указатели в стеках, регистры, глобальные переменные, и далее, указатели в куче.
    Фаза 2. Фаза маркировки: проход по графу указателей. Пометить объекты, как достижимые по ходу исполнения программы. 

    В основе работы сборщика мусора Go лежит трехцветный алгоритм
    Главный принцип алгоритма трехцветной пометки и очистки состоит в разделении объектов, находящихся в куче, на три набора, 
    в соответствии с цветом, который назначается им алгоритмом.

    black - исследованные объекты (полезные, используются в программе)
    gray - ожидающие исследования объекты
    white - неисследованные объекты

    Итак, когда начинается сборка мусора, все объекты становятся белыми. Сборщик мусора перебирает все корневые объекты и 
    окрашивает их в серый цвет. Корневые объекты — это объекты, к которым приложение может обращаться напрямую, включая 
    глобальные переменные и другие элементы, находящиеся в стеке. Большинство этих объектов зависят от Go-кода конкретной программы.

    После этого сборщик мусора выбирает серый объект, помечает его черным и проверяет, есть ли у него указатели на другие объекты из 
    белого множества. Это означает, что при проверке серого объекта на предмет указателей на другие объекты он окрашивается в черный цвет. 
    Если проверка обнаружит, что у данного объекта есть один или несколько указателей на белые объекты, алгоритм поменяет цвет этих белых 
    объектов на серый. Процесс продолжается до тех пор, пока не будут перебраны все объекты серого множества. Затем объекты белого множества 
    считаются недостижимыми, и занимаемая ими память может использоваться повторно. Таким образом, считается, что в этот момент элементы 
    белого множества попали в корзину.

    Приложение, работающее во время выполнения сборки мусора, называется мутатором. Мутатор запускает небольшую функцию, называемую 
    барьером записи. Эта функция выполняется всякий раз, когда изменяется указатель в куче. Если указатель объекта в куче изменился, 
    это означает, что данный объект теперь достижим. Барьер записи помечает этот объект в серый цвет и помещает в серое множество.
    Мутатор отвечает за то, чтобы ни один элемент из черного множества не имел указателя на элемент из белого множества. 
    Это достигается с помощью функции барьера записи.

    (!) Go позволяет запускать сборку мусора вручную. 
    Для этого нужно вставить в код Go оператор runtime.GC(). 
    Однако помните, что runtime.GC() заблокирует вызывающую функцию и может даже заблокировать всю программу, особенно если это очень 
    большая Go-программа с огромным количеством объектов. Так происходит главным образом потому, что невозможно выполнять сборку мусора, 
    когда остальное окружение быстро меняется, поскольку тогда сборщик мусора не сможет четко идентифицировать элементы белого, черного 
    и серого множеств. Такой статус сборки мусора также называется начальной точкой сборки мусора.

    Основной проблемой сборщика мусора Go является низкая латентность, что означает, в сущности, короткие паузы, чтобы обеспечить 
    его работу в реальном времени. Несмотря на свою простоту, алгоритм пометки и очистки приостанавливает выполнение работающей программы, 
    следовательно, увеличивает задержку реальных процессов. Go пытается уменьшить эту задержку, запуская сборщик мусора как параллельный 
    процесс и используя трехцветный алгоритм, описанный в предыдущем разделе. Однако другие процессы могут перемещать указатели или создавать 
    новые объекты одновременно с работой сборщика мусора. Для сборщика мусора это может сильно усложнить жизнь.

    Решением этой проблемы является корректная обработка всех ситуаций, которые могут вызвать проблему для алгоритма сборки мусора. 
    В частности, все новые объекты должны заноситься в серое множество, поскольку таким образом сохранится необходимое условие алгоритма 
    пометки и очистки. В дополнение, при перемещении указателя объект, на который ссылается этот указатель, должен помечаться серым цветом. 
    Серое множество играет роль барьера между белым и черным множествами. Наконец, при каждом перемещении указателя автоматически должен 
    выполняться некий Go-код, которым является ранее упомянутый барьер записи, изменяющий цвет объекта. Задержка, вызванная выполнением 
    кода барьера записи, — это та цена, которую приходится платить за возможность конкурентной сборки мусора.

    (!) GC не ходит (не маркирует):
        - в стеки горутин
        - в буфер буферизированного канала
        - в sync.Pool (технология повторного использования объектов)




23 defer
    Ключевое слово defer позволяет отложить выполнение функции до тех пор, пока не потребуется вернуть значение внешней функции. 
    Этот прием широко используется в операциях ввода и вывода файлов, поскольку избавляет от необходимости запоминать, когда следует 
    закрыть открытый файл. Ключевое слово defer позволяет поместить вызов функции, которая закрывает открытый файл, рядом с вызовом 
    функции, которая его открыла.

    После возвращения из внешней функции отложенные функции выполняются в порядке «последним пришел — первым вышел» (Last In, First 
    Out, LIFO). Это означает, что если сначала отложить функцию f1(), затем функцию f2() и после нее — функцию f3() в одной и той же 
    внешней функции, то, когда эта внешняя функция будет возвращать значение, функция f3() выполнится первой, функция f2() — второй, 
    а функция f1() — последней.


24 Замыкания
    В Go функции могут быть замыканиями (closures). 
    Замыкание - это функция, которая ссылается к переменным вне ее тела. 
    Функция имеет доступ к связанным переменным, а также может присваивать им значения; 
    в этом смысле функция "связана" с этими переменными.

    // ФУНКЦИИ КАК ОБЪЕКТ ПЕРВОГО КЛАССА:
    1) можем присваивать функцию в какую-то переменную              // var less func(i,j int) bool
    2) принимать функцию как аргумент в другую функцию              // func mySort(fn func(i,j int)) { if fn.less(..) ..}
    3) возвращать функцию как результат работы другой функции       
    4) функция может быть полем некторой структуры

    Замыкания, лямбды и анонимные функции-все это "функции первого класса". 
    Анонимные Функции, также называемый Лямбда функции-это функции, у которых нет имени (например, 
    способ a(ch:) имеет имя). Поскольку у них нет имени, единственный способ использовать их-сохранить 
    их в переменной или передать в качестве аргументов (параметры, по сути, являются переменными).


Базы данных

    Реляционные и NoSQL - это два типа систем баз данных, которые обычно реализуются в облачных приложениях (нвый тип - NewSQL)

        1 Реляционные БД
            Реляционные базы данных предоставляют хранилище связанных таблиц данных. 
            Эти таблицы имеют фиксированную схему, используют SQL (язык структурированных запросов) для управления данными
            и поддерживают гарантии ACID.

            Плюсы и минусы:
                +Согласованность
                +Доступность
                -Сложности с горизонтальным масштабированием
                -Данные должны быть структурированными
                -Для получения данных необходимо обращаться к нескольким таблицам
                -Сложное прототипирование приложения (усложняет разработку)

            Обычно Реляционные БД предоставляются на одном сервере и масштабируются по вертикали за счет добавления 
            дополнительных ресурсов к машине.
            
            Реляционные базы данных обычно обеспечивают согласованность и доступность, но не допускают разделение.
            Многие системы реляционных баз данных поддерживают встроенные функции репликации, при которых копии master базы данных могут быть 
            сделаны на другие slaves экземпляры. Операции записи выполняются в первичном экземпляре (master) и реплицируются на каждый из вторичных (slave) 
            экземпляров. В случае сбоя первичный экземпляр может переключиться на вторичный, чтобы обеспечить высокую доступность. 
            Хотя операции записи всегда выполняются в отношении первичной реплики, операции чтения могут быть перенаправлены на любую из вторичных реплик, 
            чтобы снизить нагрузку на систему.

            Данные также можно разделить по горизонтали на несколько узлов, например, с помощью сегментирования (шардинга).
                Минусы: 
                    -увеличение операционных издержек, поскольку данные распределяются по множеству баз, которые не могут легко обмениваться данными. 
                    -управление может быть дорогостоящим и трудоемким. 
                    -реляционные функции, которые включают соединения таблиц, транзакции и ссылочную целостность, требуют значительных потерь производительности
                    в сегментированных (в шардах) развертываниях.
            


        2 NoSQL
            Базы данных NoSQL относятся к высокопроизводительным нереляционным хранилищам данных. Они отличаются простотой использования,
            масштабируемостью, отказоустойчивостью и доступностью. Вместо объединения таблиц с нормализованными данными NoSQL хранит 
            неструктурированные или полуструктурированные данные, часто в парах ключ-значение или в документах JSON. 
            Базы данных NoSQL обычно не предоставляют гарантий ACID, выходящих за рамки одного раздела базы данных. Для сервисов большого
            объема, требующих времени отклика менее секунды, предпочтение отдается хранилищам данных NoSQL.

            Модели данных для баз данных NoSQL:
                - Document store        (иерархия в виде JSON)
                - Key-Value store       (пары ключ-значение)
                - Wide-Column store     (связанные данные хранятся в виде набора пар вложенных ключ / значение в одном столбце)
                - Graph store           (Данные хранятся в структуре графа как свойства узла)

            Плюсы и минусы:
                +Возможность хранения больших объемов неструктурированной информации.
                +Простое масштабирование, автоматически выбирается Primary
                +Устойчивость к разделению
                +Ключевые преимущества NoSQL баз в распределенных системах заключаются в процедурах шаринга и репликации.
                +Быстрая разработка    
                +Схема не определена жестко, ее не нужно менять при каждом изменении логики
                -Приложение сильно привязывается к конкретной СУБД (в случае SQL БД - язык sql универсален относительно реляционных БД)
                -Ограниченная емкость встроенного языка запросов.
                -Не проектируется модель данных, вследствие чего не оцениваются узкие места системы при проектировании
                -Трудности быстрого перехода с одной нереляционной базы данных на другую

            MongoDB сохраняет данные в коллекциях, состоящих из документов. Документ — это большой JSON объект без заранее определенного формата и схемы.

            Базы данных NoSQL обычно поддерживают высокую доступность и устойчивость к разделам. Они масштабируются по горизонтали, часто между обычными 
            серверами. Такой подход обеспечивает огромную доступность как внутри, так и между географическими регионами при меньших затратах. 
            Вы разделяете и реплицируете данные на этих машинах или узлах, обеспечивая избыточность и отказоустойчивость. 
            
            Согласованность обычно настраивается с помощью протоколов консенсуса или механизмов кворума. Они обеспечивают больший контроль при выборе компромиссов
            между настройкой синхронной и асинхронной репликации в реляционных системах.

    
        3 NewSQL
            NewSQL, расширяет ядро реляционной базы данных для поддержки как горизонтальной масштабируемости, так и масштабируемой производительности систем NoSQL.
                


    Когда необходимо использовать реляционную БД? А когда NoSQL?

    Рассмотрим хранилище данных NoSQL, когда:	                                Рассмотрим реляционную базу данных, когда:
        1 У вас есть рабочие нагрузки большого объема,                              1 Объем вашей рабочей нагрузки обычно умещается в 
            которые требуют предсказуемой задержки в                                    пределах тысяч транзакций в секунду.     
            большом масштабе (например, задержка, измеряемая 
            в миллисекундах, при выполнении миллионов транзакций 
            в секунду)	

        2 Ваши данные динамичны и часто меняются	                                2 Ваши данные сильно структурированы и требуют ссылочной целостности
        3 Отношения могут быть ненормализованными моделями                          3 Взаимосвязи выражаются посредством объединения 
            данных	                                                                    таблиц в нормализованных моделях данных.
        4 Извлечение данных простое и выражается без                                4 Вы работаете со сложными запросами и отчетами
            объединения таблиц	
        5 Данные обычно реплицируются в разных регионах и требуют                   5 Данные обычно централизованы или могут быть реплицированы 
            более точного контроля над согласованностью, доступностью                   в регионы асинхронно.
            и производительностью.	
        6 Ваше приложение будет развернуто на стандартном                           6 Ваше приложение будет развернуто на крупномасштабном 
            оборудовании, например, в общедоступных облаках.	                        оборудовании высокого класса.




    Горизонтальное и вертикальное масштабирование БД
        Горизонтальное масштабирование относится к добавлению или удалению баз данных для регулировки емкости или общей производительности.
        Шардинг, при котором данные распределяются по коллекции идентично структурированных баз данных, является распространенным способом 
        реализации горизонтального масштабирования.

        Вертикальное масштабирование относится к увеличению или уменьшению вычислительных мощностей сервера отдельной базы данных.
        Большинство облачных приложений баз данных используют комбинацию этих двух стратегий.

            Горизонтальное                  VS          Вертикальное масштабирование
            + отказоустойчивость                        + скорость работы системы, простота установки
            - скорость передачи по сети                 - сбой повлечет крах системы



    Шардирование
        Шардинг - это метод распределения больших объемов идентично структурированных данных по нескольким независимым базам данных. 
        Он особенно популярен среди разработчиков облачных сред, создающих предложения 

        Для чего нужен шардинг?
            -Общий объем данных слишком велик, чтобы соответствовать ограничениям отдельной базы данных.
            -Пропускная способность общей рабочей нагрузки превышает возможности отдельной базы данных.
            -Арендаторам может потребоваться физическая изоляция друг от друга, поэтому для каждого 
                клиента необходимы отдельные базы данных.
            -Разным разделам базы данных может потребоваться размещение в разных регионах по причинам 
                соответствия требованиям, производительности или геополитическим причинам.

        Например, можем создать набор из 7 баз данных, в которые будут записываться данные в зависимости от дня недели.
        тогда ключом сегментирования - будет номер дня недели.

        Когда использовать шардинг?
            Шардинг работает лучше всего, когда каждая транзакция в приложении может быть ограничена одним значением ключа сегментирования.
            Это гарантирует, что все транзакции являются локальными для конкретной базы данных.
            т.е. когда нет сложного запроса (с Join-ами)


    Репликация:
        Репликация — это синхронное или асинхронное копирование данных между несколькими серверами (избыточность). 
        Это позволяет добиться большей отказоустойчивости и масштабируемости системы.
        
        Виды:
            1) master-slave — это один мастер-сервер и несколько дочерних серверов. 
                Запись может производиться только на мастер-сервер, который передает изменения на дочерние машины. 
                Этот тип репликации даёт хорошую масштабируемость на чтение, но не на запись, так как запись идет 
                только на мастер-сервер. Этот тип репликации имеет свой минус — в случае неисправности мастер-сервера 
                нужно выбирать(автоматически или вручную) новый мастер-сервер.

            2) peer-to-peer — все узлы равны в возможности обслуживать запросы на чтение и запись. Информация о обновлении 
            данных передается от сервера к серверу.

        Если бы реплики данных потеряли сетевое соединение в «высокосогласованном» или синхронном кластере реляционной базы данных, 
        вы не смогли бы производить запись в базу данных. Система отклонит операцию записи, поскольку она не может реплицировать это 
        изменение на другую реплику данных. Каждая реплика данных должна обновиться до завершения транзакции.



    Когда использовать репликацию, а когда шардинг?
        Репликация                                                          Шардинг
            -Многие приложения только читают данные                             - Когда функциональное разбиение и репликация не помогают
                                                                                - “Единственное” решение для крупного масштаба
 



    Теорема CAP - набор принципов, применяемых к распределенным системам, хранящим состояние
        Теорема утверждает, что распределенные системы данных будут предлагать компромисс между 
            -согласованностью               (CONSISTENCY)
            -доступностью                   (AVAILABILITY)
            -устойчивость к разделению      (PARTITION TOLERANCE)
        
        И что любая база данных может гарантировать только два из трех свойств:
            -Cогласованность:               вы получите самые свежие данные, но за это придется ждать ответа, пока все реплики обновятся (необновленные узлы перестанут отвечать).
            -Доступность:                   вы получите ответ быстро, но не факт, что данные в ответе - актуальные.
            -Устойчивость к разделению:     вы получите гарантию, что ответ придет, даже в случае отказа реплики.



    PACELC (теорема "ПЭЙСЕЛК"):
        Если произошло разделение системы на несколько частей:
            то вы должны выбрать либо:
                - согласованность   (долго обслуживать пользователя, но актуальными данными)
                - доступность       (быстро обслуживать пользователя, но, возможно, неактуальными данными)
        Иначе (если система работает штатно):
            то вы должны выбрать либо:
                - согласованность   (долго обслуживать пользователя, но актуальными данными)
                - латентность       (минимальное время ожидания при получении ответа на запрос пользователя)






    Транзакция: "Упорядоченное множество операций, переводящих базу данных из одного согласованного состояния в другое"

    ACID: Требования ACID — набор требований, которые обеспечивают сохранность ваших данных. 
          ACID - основные требованиях к транзакционной системе.

        Atomicity — Атомарность (каждая транзакция будет выполнена полностью или не будет выполнена совсем)
        Consistency — Согласованность (каждая успешная транзакция по определению фиксирует только допустимые результаты)
        Isolation — Изолированность (Во время выполнения транзакции параллельные транзакции не должны оказывать влияния на её результат)
        Durability — Надёжность (транзакция завершена, клиент получил подтверждение — данные зафиксированы и постоянны)


     Но к каким эффектам может привести параллельная работа двух транзакций (Изолированность)?
        1 эффект: "Потерянное обновление (Lost Update)" - Когда несколько транзакций что-то обновили в БД, но по итогам результат такой, 
            будто отработала лишь часть транзакций. Самый опасный побочный эффект, по сути, полное отсутствие изоляции транзакций
        
        2 эффект: "Грязное чтение (Dirty Read)" - Транзакция читает данные, записанные параллельной незавершённой транзакцией.
        
        3 эффект: "Неповторяющееся чтение (Non-Repeatable Read)" - одинаковый запрос в одной транзакции может вернуть разные данные
            
        4 эффект: "Фантомное чтение (Phantom Reads)" - одинаковый запрос может вернуть НОВЫЕ строки, которые были закомичены из другой транзакции.

        5 эффект: "Аномалия сериализации" - Результат успешной фиксации группы транзакций оказывается несогласованным при всевозможных
            вариантах исполнения этих транзакций по очереди.
        вакуум?

        Для понимания этих эффектов, надо держать в уме, что речь всегда идёт о взаимодействии двух и более транзакций одновременно, 
        а сам побочный эффект — это когда желаемый результат не совпал с реальным.


    Уровни изоляции транзакций (Postgres) гарантируют отсутствие разных (с каждым разом всё более сложных) побочных эффектов.
        В стандарте SQL описывается четыре уровня изоляции транзакций:
            -Read uncommited (Чтение незафиксированных данных), 
            -Read committed (Чтение зафиксированных данных) - по умолчанию в Postgres, 
            -Repeatable read (Повторяемое чтение),
            -Serializable (Сериализуемость).


            Таблица уровней изоляции и побочных эффектов, которые могут возникнуть (прим: все режимы гарантируют отсутствие потерянных обновлений)
                Уровень изоляции    «Грязное» чтение    Неповторяемое чтение    Фантомное чтение    Аномалия сериализации
                Read uncommited 		    +                   +	                   +	                 +
                Read committed              -	                +	                   +	                 +
                Repeatable read             -                   -	                   +                     +
                Serializable                -   	            -                      -	                 -



            Read uncommited (Чтение незафиксированных данных)
                Ничего не происходит в режиме read uncomitted. То есть ничего не блокируется и не создаются снэпшоты, транзакция просто читает всё что хочет.

            Read committed (Чтение зафиксированных данных) -  отсутсвие dirty reads
                запрос SELECT видит снимок базы данных в момент начала выполнения запроса. 
                Однако SELECT видит результаты изменений, внесённых ранее в этой же транзакции, даже если они ещё не зафиксированы. 
                Также заметьте, что два последовательных оператора SELECT могут видеть разные данные даже в рамках одной транзакции, 
                если какие-то другие транзакции зафиксируют изменения после запуска первого SELECT, но до запуска второго.
            
            Repeatable read (Повторяемое чтение)
                запрос SELECT в одной транзакции видят одни и те же данные; они не видят изменений, внесённых и зафиксированных другими 
                транзакциями после начала их текущей транзакции. 
                Однако SELECT видит результаты изменений, внесённых ранее в этой же транзакции, даже если они ещё не зафиксированы.
            
            Serializable (Сериализуемость)
                Уровень Serializable обеспечивает самую строгую изоляцию транзакций. На этом уровне моделируется последовательное выполнение 
                всех зафиксированных транзакций, как если бы транзакции выполнялись одна за другой, последовательно, а не параллельно.
                Из "конкурирующих" транзакций, изменяющие одни и те же данные зафиксируется только одна из них, остальные - 
                откатятся (аномалия сериализации) с сообщением:
                    ОШИБКА: не удалось сериализовать доступ из-за зависимостей чтения/записи между транзакциями



        Подходы к реализации уровней изоляции транзакции:
            - Блокировки — это когда мы блокируем данные в базе. Можно заблокировать одну строку в таблице, а можно всю таблицу. 
            Можно заблокировать данные на редактирование, а можно и на чтение тоже. Одна транзакция будет ждать другую, чтобы избежать
            побочных эффектов, в зависимости от строгости уровней изоляции этих транзакций
            
            - Версионирование (snapshot) — это когда внутри базы при каждом обновлении создается новая версия данных и сохраняется старая. 
            Версионирование скрыто от разработчика, то есть мы не видим в базе никаких номеров версий и данных по ним. 
            Просто пока транзакция, обновляющая запись, не покомитит свое изменение, остальные потребители читают старую 
            версию записи и не блокируются. Другими словами, транзакции будут работать со своей копией данных, не влияя друг на друга, 
            но впоследствии несколько изменённых копий надо будет как-то слить в одну. Строгость версионирования регулирует моменты (когда) 
            и размеры (сколько данных копировать) этих копий.




    Что такое индексирование?

        INDEXING — это метод структуры данных, который позволяет вам быстро извлекать записи из файла базы данных. Индекс — это небольшая таблица, 
        имеющая всего два столбца. Первый столбец содержит копию первичного или потенциального ключа таблицы. Его второй столбец содержит набор 
        указателей для хранения адреса дискового блока, где хранится это конкретное значение ключа.
            
            Индекс —
                Принимает ключ поиска в качестве ввода
                Эффективно возвращает коллекцию совпадающих записей.

        Индексация базы данных определяется на основе ее атрибутов индексации. Два основных типа методов индексации:        
            1 Первичная индексация (Первичный индекс — это упорядоченный файл с фиксированной длиной и двумя полями)
            2 Вторичная индексация (Вторичный индекс — это метод индексации, ключ поиска которого определяет порядок, отличный от 
                                    последовательного порядка файла)

        1 Первичная индексация
            Первичный индекс — это упорядоченный файл с фиксированной длиной и двумя полями. Первое поле — это тот же 
            первичный ключ, а второе поле указывает на этот конкретный блок данных. В первичном индексе всегда существует 
            отношение один к одному между записями в таблице индекса.

            Первичная индексация также делится на два типа.
                Плотный индекс          (запись создается для каждого поискового ключа, оцененного в базе данных)
                Разреженный индекс      (Метод разреженной индексации помогает решить проблемы плотной индексации)

        2 Вторичный индекс может быть создан с помощью поля, которое имеет уникальное значение для каждой записи, и это должен быть ключ-кандидат. 
            Он также известен как некластеризованный индекс.
            Этот двухуровневый метод индексации базы данных используется для уменьшения размера отображения первого уровня. 
            Для первого уровня из-за этого выбирается большой диапазон чисел; размер отображения всегда остается небольшим.


        Индекс кластеризации определяется как файл данных заказа.
        Многоуровневое индексирование создается, когда первичный индекс не помещается в памяти.
        Самым большим преимуществом индексирования является то, что оно помогает вам сократить общее количество операций ввода-вывода, необходимых для извлечения этих данных.
        Самый большой недостаток для выполнения системы управления базами данных индексации, вам нужен первичный ключ в таблице с уникальным значением.


    индексы и как устроены
        Индексы представляют собой структуру, позволяющую выполнять ускоренный доступ к строкам таблицы на основе
        значений одного или более ее столбцов.

        Физически индекс – всего лишь упорядоченный набор значений из индексированного столбца с указателями на 
        места физического размещения исходных строк в структуре базы данных.

        Когда пользователь выполняет обращающийся к индексированному столбцу запрос, СУБД автоматически анализирует 
        индекс для поиска требуемых значений.
        
        Однако, поскольку индексы должны обновляться системой при каждом внесении изменений в их базовую таблицу, 
        они создают дополнительную нагрузку на систему.

        Существует два типа индексов: кластерные и некластерные. При наличии кластерного индекса строки таблицы 
        упорядочены по значению ключа этого индекса. Если в таблице нет кластерного индекса, таблица называется 
        кучей. Некластерный индекс, созданный для такой таблицы, содержит только указатели на записи таблицы.

    
    Менеджеры соединений: Pgpool и PgBouncer
        Пока мы переезжали, продукт тоже развивался: увеличивалось количество пользователей и количество серверов, которые работали с
        PostgreSQL, и нам стало не хватать соединений. PostgreSQL на каждое соединение создаёт отдельный процесс и потребляет ресурсы. 
        Увеличивать число коннектов можно до определённого момента, иначе есть шанс получить неоптимальную работу БД. Идеальным вариантом 
        в такой ситуации будет выбор менеджера коннектов, который встанет перед базой.

        У нас было два варианта для менеджера соединений: Pgpool и PgBouncer. Но первый не поддерживает транзакционный режим работы с 
        базой, поэтому мы выбрали PgBouncer.

    PGBouncer
        PgBouncer – это мультиплексор соединений к БД, его использование обусловлено тем, что приложения могут плодить сотни 
        коннектов к базе – а в postgresql схема работы такова, что “один коннект == один процесс”: соответственно, кол-во одновременно 
        работающих коннектов(процессов) не сможет превышать кол-во ядер процессора.

        PgBouncer позволяет группировать подключения к бд по связке “username/database”, и использовать тем самым одно подключение к БД 
        для разных коннектов приложений. В некоторых случаях это позволяет неплохо сэкономить ресурсы и не дёргать базу лишний раз.



    BTree VS BTree+
        Ключевое отличие: В компьютерах двоичные деревья представляют собой древовидные структуры данных, которые хранят данные и позволяют 
        пользователю получать доступ, искать, вставлять и удалять данные в алгоритмическое время. Различие между деревом B и B + состоит в том,
        что в B-дереве ключи и данные могут храниться как во внутренних, так и в конечных узлах, тогда как в дереве B + данные и ключи могут 
        храниться только в конечных узлах.  

        Преимущества деревьев B +:
            Поскольку деревья B + не имеют данных, связанных с внутренними узлами, на странице памяти может поместиться больше ключей. 
            Следовательно, для доступа к данным, которые находятся на листовом узле, потребуется меньше промахов в кэше.
            Листовые узлы деревьев B + связаны, поэтому для полного сканирования всех объектов в дереве требуется всего один линейный проход через 
            все листовые узлы. Дерево AB, с другой стороны, потребовало бы обхода каждого уровня в дереве. Этот обход всего дерева, вероятно, 
            будет включать больше промахов кеша, чем линейный обход листьев B +.

        Преимущество B-деревьев:
            Поскольку B-деревья содержат данные с каждым ключом, часто используемые узлы могут располагаться ближе к корню, и, следовательно, 
            к ним можно обращаться быстрее.

        B-Tree Index
            Индекс B-дерева — это широко используемые структуры данных для индексации. Это метод многоуровневого индексного формата, 
            который сбалансирован бинарными деревьями поиска. Все конечные узлы дерева B обозначают фактические указатели данных.

            Более того, все конечные узлы связаны между собой списком ссылок, что позволяет дереву B поддерживать как произвольный, 
            так и последовательный доступ.




    Организация хранения данных ?
        Табличный файл по умолчанию состоит из блока размером 8 КБ, а 8 КБ является базовой единицей чтения и записи базы данных.




Сети

    Протоколы tcp, udp, http

        Протокол обмена данными — это подробная инструкция о том, какого типа информация передается по сети, в каком 
        порядке обрабатываются данные, а также набор правил обработки этих данных.

        Существуют два принципа организации обмена данными в вычислительных сетях:
            -установление виртуального соединения с подтверждением приема каждого пакета (более надежный принцип, предпочтителен
                при передачи данных на большие расстояния. Если какой-то пакет принят неправильно, отправитель повторяет его передачу);
            -передача датаграмм (короткие пакеты — собственно датаграммы — пересылаются адресату без подтверждения 
                получения каждой из них. О получении всего сообщения целиком должна уведомить целевая программа).


        За время развития вычислительных сетей было предложено и реализовано много протоколов обмена данными, 
        самыми удачными из которых явились семейство протоколов TCP/IP (Transmission Control Protocol/Internet Protocol — протокол 
        управления передачей/межсетевой протокол).

        ТСР/IР — это набор протоколов, состоящий из следующих компонентов (основные сетевые протоколы сети Интернет):
            -IP, межсетевой протокол (Internet Protocol), обеспечивающий адресацию в сетях (IP-адресацию), доставку сетевых пакетов;
            -ICMP, межсетевой протокол управления сообщениями (Internet Control Message Protocol—ICMP), который обеспечивает низкоуровневую 
                поддержку протокола IP, включая такие функции, как сообщения об ошибках, квитанции, содействие в маршрутизации и т.п.;
            -ARP, протокол разрешения адресов (Address Resolution Protocol -ARP), выполняющий преобразование логических сетевых адресов в 
                аппаратные, а также обратный ему RARP (Reverse ARP);
            -UDP, протокол пользовательских датаграмм (User Datagramm Protocol – UDP);
            -TCP, протокол управления передачей (Transmission Control Protocol — TCP) - устанавливает надежное соединение, между двумя 
                машинами и собственно пеpедачу данных, контpолиpуя оптимальный pазмеp пакета пеpедаваемых данных и осуществляя пеpепосылку 
                в случае сбоя.

        IP - протокол сетевого уровня, описывающий формат пакета данных, передаваемого по сети
        TCP – транспортный протокол передачи данных в сетях TCP/IP, предварительно устанавливающий соединение с сетью.
        UDP – транспортный протокол, передающий сообщения-датаграммы без необходимости установки соединения в IP-сети.

        TCP/IP — сетевая модель передачи данных, представленных в цифровом виде
        В заголовке TCP/IP пакета указывается:
            IP-адрес отправителя
            IP-адрес получателя
            Номер порта      (Фактически - номер прикладной программы,
                                которой этот пакет предназначен)

        Модель TCP/IP иерархическая и включает четыре уровня:
        -----------|-----------------|------------------------------------------------                              
        Уровень         Название         Функция
           4            Прикладной       Приложения пользователей, создание сообщений (HTTP, FTP, Telnet, SSH, DNS, SMTP...)
           3           Транспортный      Доставка данных между программами в сети (TCP, UDP)
           2             Сетевой         Адресация и маршрутизация (IP, ARP, ICMP)
           1            Канальный        Сетевые аппаратные средства и их драйверы


        4 Прикладной уровень определяет способ общения пользовательских приложений. В системах, клиент-сервер, приложение-клиент должно знать, 
            как посылать запрос, а приложение-сервер должно знать, как ответить на запрос. Этот уровень обеспечивает такие протоколы, как HTTP, FTP, Telnet.

        3 Транспортный уровень позволяет сетевым приложениям получать сообщения по строго определенным каналам с конкретными параметрами.

        2 На сетевом уровне определяются адреса включенных в сеть компьютеров, выделяются логические сети и подсети, реализуется маршрутизация между ними.
        
        1 На канальном уровне определяется адресация физических интерфейсов сетевых устройств, например сетевых плат. К этому уровню относятся программы 
            управления физическими сетевыми устройствами, так называемые драйверы.

    
        Процесс передачи сообщения по сети TCP/IP:
            1 Сообщение (сформированное на прикладном уровне) разбивается на пакеты, или датаграммы. Пакет, или датаграмма — это часть 
                сообщения с добавленным заголовком пакета или датаграммы.
            2 На транспортном уровне к полезной информации добавляется заголовок — служебная информация. 
            3 Для сетевого уровня полезной информацией является уже пакет, или датаграмма транспортного уровня. К ним добавляется заголовок сетевого уровня.
                Полученный блок данных называется IP-пакетом. Полезной нагрузкой для канального уровня является уже IP-пакет. Здесь перед 
                передачей по каналу к нему добавляются собственный заголовок и еще завершитель. Получившийся блок называется кадром. 
                Он и передается по сети.
            4 Переданный по сети кадр в пункте назначения преобразуется в обратном порядке, проходя по уровням модели снизу вверх.



    Модель OSI (https://community.fs.com/ru/blog/tcpip-vs-osi-whats-the-difference-between-the-two-models.html)
        Модель ISO OSI предписывает очень сильную стандартизацию вертикальных межуровневых взаимодействий. 
        Такая стандартизация гарантирует совместимость продуктов, работающих по стандарту какого-либо уровня, с продуктами, 
        работающими по стандартам соседних уровней, даже в том случае, если они выпущены разными производителями.
        
        Модель OSI является общей, независимой от протокола, но большинство протоколов и систем придерживаются ее, в то время как 
        модель TCP/IP основана на стандартных протоколах, которые разработал интернет.  

        В многоуровневой системе, устройства уровня обмениваются данными в другом формате, который известен как protocol data unit (PDU). 
        В таблице ниже показаны PDU на разных уровнях. 
        ----------------------|------------------------|-----------------------------------|---------------------------                              
        Тип модели 	            Уровни OSI 	                Protocol Data Unit (PDU) 	        Уровни TCP/IP
            Уровни хоста 	    7 Прикладной уровень 	     |      Данные      | 	            4 Прикладной уровень
                                6 Уровень представления 	 |      Данные      |                 Сеансовый уровень
                                5 Сеансовый уровень 	     |      Данные      |                 Применение
                                4 Транспортный уровень 	   Segment (TCP) / Datagram (UDP) 	    3 Транспортный уровень
            ________________ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
            Уровни медиа 	    3 Сетевой уровень 	                Пакет 	                    2 Сетевой уровень
                                2 Канальный уровень 	             Кадр 	                    |1 Канальный уровень|
                                1 Физический уровень 	             Бит                        |1 Канальный уровень|


        Взаимосвязь уровней OSI и TCP/IP
            OSI Model                       TCP/IP Model                            TCP/IP Protocol Suite
        ----------------------|------------------------------------------|--------------------------------------------
        7 Application layer   |                                          | 
        6 Presentation layer  |           4 Application layer            | Http, Smtp, Telnet, FTP, DNS, RIP, SNMP
        5 Session layer       |__________________________________________|____________________________________________
        4 Transport layer     |            3 Transport layer          -> |->          TCP, UDP
        3 Network layer       |     2 Network layer (Internet layer)  -> |->       ARP, IP, IGMP, ICMP     
        2 Data link layer     |------------------------------------------|---------------------------------------------
        1 Physical layer      |          1 Network Access layer          | Ethernet, Token Ring, ATM, Frame Relay


        Модель TCP/IP и модель OSI являются концептуальными моделями, используемыми для описания всех сетевых коммуникаций, в 
        то время как TCP/IP сама по себе также является важным протоколом, используемым во всех операциях Интернета. Как правило, 
        когда мы говорим об уровне 2, уровне 3 или уровне 7, в котором работает сетевое устройство, мы имеем в виду модель OSI. 
        Модели TCP/IP используется как для моделирования текущей архитектуры Интернета и обеспечивают набор правил, которым следуют 
        все формы передачи по сети.

        7 Прикладной уровень - доступ к сетевым службам (DNS, WWW/HTTP, P2P, EMAIL/POP, SMTP, Telnet, FTP)
        6 Уровень представления - представление и шифрование данных (Recognizing data: HTML, DOC, JPEG, MP3, AVI, Sockets)
        5 Сеансовый - управление сеансом связи (TCP, SIP, RTP, RPC-named pipes)
        4 Транспортный - прямая связь между конечными пунктами и надежность (TCP, UDP, SCTP, SSl, TLS)
        3 Сетевой уровень - определение маршрута и логическая адресация (IP, ARP, IPsec, ICMP, IGMP, OSPF)
        2 Канальный - физическая адресация (Ethernet, 802.11, MAC/LLC, VLAN, ATM, HDP, Fibre Channel, Frame Relay, HDLC, PPP, Q921, Token Ring)
        1 Физический - работа со средой передачи, сигнлами и двоичными данными (RS-232, Rj 45, V 34, 100Base-TX, SDH, DSL, 802.11)



    HTTP
        HTTP — широко распространённый протокол передачи данных, изначально предназначенный для передачи гипертекстовых документов 
        (то есть документов, которые могут содержать ссылки, позволяющие организовать переход к другим документам).
        HTTP является протоколом верхнего, прикладного уровня OSI (7 уровень), TCP/IP (4 уровень)

        Протокол HTTP предполагает использование клиент-серверной структуры передачи данных. 
        Задача, которая традиционно решается с помощью протокола HTTP — обмен данными между пользовательским приложением, 
        осуществляющим доступ к веб-ресурсам (обычно это веб-браузер) и веб-сервером.

        API многих программных продуктов также подразумевает использование HTTP для передачи данных — сами данные при этом могут 
        иметь любой формат, например, XML или JSON.

        Как правило, передача данных по протоколу HTTP осуществляется через TCP/IP-соединения. 
        Серверное программное обеспечение при этом обычно использует TCP-порт 80 (и, если порт не указан явно, то обычно клиентское 
        программное обеспечение по умолчанию использует именно 80-й порт для открываемых HTTP-соединений), хотя может использовать и любой другой.


        Для формирования HTTP-запроса необходимо:
            -составить стартовую строку запроса (Метод URI HTTP/Версия, например GET / HTTP/1.1)
            -задать заголовок (как минимум host, который преобразуется в IP-адрес на стороне клиента)


            Первая строка HTTP-запроса называется линией запроса и состоит из трёх частей:
                "method"  указывает, какой это запрос. Наиболее распространённые методы GET, POST и HEAD (Когда вы отправляете запрос HEAD, это означает, что 
                                                                                            вас интересуют только код ответа и HTTP headers,  а не сам документ).
                "path" , как правило, является частью URL-адреса, который идёт после host (домена). Например, если 
                    запрос "https://net.tutsplus.com/tutorials/other/top-20-mysql-best-practices/" , часть path будет "/tutorials/other/top-20-mysql-best-practices/".
                Часть "protocol" содержит "HTTP" и версию, которая обычно 1.1 в современных браузерах.

            Остальная часть запроса содержит HTTP headers как пары "Name: Value" в каждой строке. 
            Они содержат различную информацию о HTTP-запросе и вашем браузере. 

            пример HTTP-запроса
                GET /tutorials/other/top-20-mysql-best-practices/ HTTP/1.1                      // строка запроса (обязательна)
                Host: net.tutsplus.com                                                          // host - тоже обязателен. Host-заголовок. Все, что ниже - тоже заголовки
                User-Agent: Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.5) Gecko/20091102 Firefox/3.5.5 (.NET CLR 3.5.30729)
                Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
                Accept-Language: en-us,en;q=0.5
                Accept-Encoding: gzip,deflate
                Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7
                Keep-Alive: 300
                Connection: keep-alive
                Cookie: PHPSESSID=r2t5uvjq435r4q7ib3vtdjq120
                Pragma: no-cache
                Cache-Control: no-cache


        Http-глаголы (методы) - определяют операцию, которую нужно осуществить с указанным ресурсом.
        URI (унифицированный идентификатор ресурса) - путь до конкретного ресурса (например, документа), над которым необходимо осуществить операцию 

        Для чтения ответа:
            Стартовая строка ответа имеет следующую структуру:
                HTTP/Версия Код состояния Пояснение
            
                Версия протокола здесь задаётся так же, как в запросе.
                Код состояния (Status Code) — три цифры (первая из которых указывает на класс состояния), которые определяют результат совершения запроса
                Пояснение к коду состояния (Reason Phrase) — текстовое пояснение к коду ответа, предназначено для упрощения чтения ответа человеком. 

                После того, как браузер отправляет HTTP-запрос, сервер отвечает HTTP-ответом
                protocol        status code
                HTTP headers as key:value


                После стартовой строки следуют заголовки, а также тело ответа. Например:
                    HTTP/1.1 200 OK
                    Server: nginx/1.2.1
                    Date: Sat, 08 Mar 2014 22:53:46 GMT
                    Content-Type: application/octet-stream
                    Content-Length: 7                               // для определения окончания тела ответа
                    Last-Modified: Sat, 08 Mar 2014 22:53:30 GMT
                    Connection: keep-alive
                    Accept-Ranges: bytes                            

                    Wisdom                                          // тело ответа

                
                    HTTP/1.1 302 Moved Temporarily
                    Server: nginx
                    Date: Sat, 08 Mar 2014 22:29:53 GMT
                    Content-Type: text/html
                    Content-Length: 154
                    Connection: keep-alive
                    Keep-Alive: timeout=25
                    Location: http://habrahabr.ru/users/alizar/

                    <html>                                          // тело ответа
                    <head><title>302 Found</title></head>
                    <body bgcolor="white">
                    <center><h1>302 Found</h1></center>
                    <hr><center>nginx</center>
                    </body>
                    </html>




    HTTP/1.1 vs HTTP/2.0
        HTTP/1.1 (HTTP, HyperText Transfer Protocol) – это сетевой протокол верхнего уровня для передачи данных в виде 
        гипертекстовых документов в формате HTML и произвольных данных. С помощью данного протокола браузер принимает 
        данные от серверов, а затем показывает их в читабельном и эстетичном для пользователей виде. Также сервер 
        посредством HTTP браузера посылает серверу пользовательские данные.

        HTTP/2 (HTTP/2.0) – вторая масштабная версия сетевого протокола HTTP, созданная на базе протокола прикладного 
        уровня SPDY для доступа к Всемирной паутине.

        Дефекты HTTP / 1.x
            Клиенту необходимо использовать несколько подключений для достижения параллелизма и уменьшения задержки;
            Не сжимает заголовки запроса и ответа, что приводит к ненужному сетевому трафику;
            Не поддерживает эффективный приоритет ресурсов, что приводит к низкому использованию базовых TCP-соединений.

        Отличия
            -HTTP/2 стал первым бинарным протоколом (чтобы сделать формирование пакетов проще)
            -В HTTP/2 изменены методы распределения данных на фрагменты и их отправка от сервера к пользователю и наоборот. 
            -HTTP/2 позволяет серверам доставлять информацию, которую клиент пока что не запросил. Это было внедрено
                с той целью, чтобы сервер сразу же отправлял браузеру для отображения документов дополнительные файлы и избавлял 
                его от необходимости анализировать страницу и самостоятельно запрашивать недостающие файлы.
            -Еще одно отличие http 2.0 от версии 1.1 – мультиплексирование запросов и ответов для решения проблемы
                блокировки начала строки, присущей HTTP 1.1. Еще в новом протоколе можно сжимать HTTP заголовки и вводить 
                приоритеты для запросов.

         Протокол HTTP/2 существенно ускоряет открытие сайтов за счет следующих особенностей:
            -соединения: несколько запросов могут быть отправлены через одно TCP-соединение, и ответы могут быть получены в любом порядке.
                Отпадает необходимость держать несколько TCP-соединений;
            -приоритеты потоков: клиент может задавать серверу приоритеты — какого типа ресурсы для него более важны, чем другие;
            -сжатие заголовка: размер заголовка HTTP может быть сокращен;
            -push-отправка данных со стороны сервера: сервер может отправлять клиенту данные, которые тот еще не запрашивал, 
                например, на основании данных о том, какую следующую страницу открывают пользователи.






    Выбор Request-Response парадигмы API: REST, RPC или GraphQL?
        API определяет интерфейс, предоставляющий данные сервиса другим приложениям. 
        
        Request-Response API. Основные отличия данной группы:
            -Интерфейс предоставляется через веб-сервер на основе HTTP протокола.
            -API определяет набор эндпоинтов.
            -Клиенты отправляют запросы для работы с данными(получить/удалить/изменить) на данные эндпоинты.
            -Ответ в формате JSON или XML.

        Самые популярные request-response API: REST, RPC и GraphQL.

        REST (от англ. Representational State Transfer — «передача состояния представления») — архитектурный стиль взаимодействия компонентов распределённого 
            приложения в сети. REST представляет собой согласованный набор ограничений, учитываемых при проектировании распределённой гипермедиа-системы.

            Самый популярный подход на данный момент.
            Ресурс — это объект, который может быть идентифицирован, назван, адресован или обработан в сети. 
            REST представляет данные как ресурсы и использует стандартные HTTP-методы для управления этими ресурсами (CRUD). 

            В отличие от SOAP, REST — это не протокол, а архитектурный стиль. 
            Архитектура REST устанавливает набор рекомендаций, которым необходимо следовать, если вы хотите предоставить веб-службу RESTful, 
            например, существование без сохранения состояния и использование кодов состояния HTTP.

            Общие правила, которым следует RESTful API:
                -Ресурс является частью URL.
                -Существительные вместо глаголов, вместо /getUserInfo/123 используем /users/123.
                -Для каждого ресурса создается два URL, один для коллекции, один для экземпляра коллекции, /users и users/123.
                -HTTP-методы GET, POST, UPDATE и DELETE информируют сервер о том, какое действие нужно совершить над данным ресурсом. 
                    Различные методы, примененные к одному и тому же ресурсу, выполняют различную функциональность.
                -Стандартные коды состояния ответа HTTP возвращаются сервером, указывая на успех или неудачу. Как правило, коды в 
                    диапазоне 2XX указывают на успех, коды 3XX указывают на перемещение ресурса, а коды в диапазоне 4XX указывают на 
                    ошибку на стороне клиента (например, отсутствие обязательного параметра или слишком много запросов). Коды в 
                    диапазоне 5XX указывают на ошибки на стороне сервера.
                -Ресурс, который существует только в другом ресурсе, должен быть представлен как подресурс, а не как ресурс верхнего 
                    уровня в URL-адресе. Например issues не могут существовать отдельно от репозитория, поэтому URL создания нового 
                    issue в GitHub API выглядит таким образом — /repos/:owner/:repo/issues

            Помимо типичных операций CRUD, API-интерфейсы REST могут иногда нуждаться в представлении операций, не относящихся к CRUD.
            В этом случае обычно используются следующие подходы:
                -Передавать действие в теле метода. Например, GitHub использует данный подход для архивации репозитория (прим. PATCH /repos/:owner/:repo).
                -Трактовать действие как подресурс. API GitHub использует этот шаблон для блокировки и разблокировки issue (прим. PUT /repos/:owner/:repo/issues/:number/lock).
                -Использовать отдельный ресурс. Некоторые операции, такие как поиск, ещё сложнее вписать в парадигму REST. Типичная практика в этом случае — 
                    использовать только команду действия в URL-адресе API (прим. GET /search/code?q=:query).

            Плюсы:
                +Стандартное имя метода, формат аргументов и коды состояния.
                +Использует функционал HTTP.
                +Легко поддерживать.

            Минусы:
                -Большой payload.
                -Множественные HTTP-запросы.

            Когда использовать:
                Для API, предоставляющего CRUD-операции.



        Remote Procedure Call (RPC)
            Удаленный вызов процедур (RPC) — это одна из простейших парадигм API, в которой клиент вызывает исполнение блока кода на сервере. 
            В то время как REST рассматривает всё как ресурсы, RPC рассматривает действия. Клиенты обычно передают имя метода и аргументы серверу 
            и получают обратно JSON или XML.

            Правила RPC:
                -Эндпоинты содержат имя выполняемой операции.
                -Вызовы API выполняются с помощью наиболее подходящего HTTP-глагола: GET для запросов только для чтения и POST для других.

            Пример:
                POST /api/conversations.archive 
                HOST slack.com 
                Content-Type: application/x-www-form-urlencoded 
                Authorization: token OAUTH-TOKEN 

                channel=C01234 

            Плюсы:
                +Очень прост.
                +Легковесный payload.
                +Высокая производительность.

            Минусы:
                -Труден в обнаружении.
                -Практически нет стандартизации.
                -Может быть создано слишком много эндпоинтов.

            Когда использовать:
                Для API, предоставляющего действия, которые сложно инкапсулировать в CRUD операциях.
            

   
        GraphQL
            GraphQL — это язык запросов для API, который в последнее время приобрел значительную популярность. 
            Он был разработан внутри Facebook в 2012 году до публичного выпуска в 2015 году. GraphQL позволяет клиентам определять 
            структуру требуемых данных. Сервер возвращает именно эту структуру

            Пример запроса:
                POST /graphql 
                HOST api.github.com 
                Content-Type: application/json 
                Authorization: bearer OAUTH-TOKEN 
                { 
                    user(login: "kliukovkin") { 
                        id 
                        name 
                        company 
                        createdAt 
                    } 
                } 

                Пример ответа:
                {   "data": { 
                        "user": { 
                            "id": "MDQ6VXNlcjY1MDI5", 
                            "name": "Georgii Kliukovkin", 
                            "company": "myCompany", 
                            "createdAt": "2009-03-19T21:00:06Z" 
                        } 
                    } 
                } 

                В отличие от REST и RPC API, GraphQL требует только один эндпоинт URL. 
                Также вам не нужны разные HTTP-методы для описания операции. Вместо этого вы указываете в теле JSON выполняете ли вы запрос или мутацию. 
                GraphQL поддерживает методы GET и POST.

                Плюсы:
                    +Один запрос.
                    +Возможность добавлять новые поля и типы в GraphQL API, не затрагивая существующие запросы.
                    +Проще отказаться от использования существующих полей.
                    +Выполняя анализ логов, поставщик API может выяснить, какие клиенты используют определённое поле.
                        Вы можете скрыть устаревшие поля и удалить их, когда их не используют клиенты. 
                        С REST и RPC API сложнее определить, какие клиенты используют устаревшее поле, что затрудняет удаление.
                    +Small payload.
                    +GraphQL строго типизирован. Во время разработки проверка типов GraphQL помогает гарантировать, что запрос 
                        синтаксически верен и действителен.
                    +GraphiQL — встроенная в браузер IDE для изучения GraphQL. Данный инструмент позволяет пользователям писать, 
                        проверять и тестировать запросы GraphQL в браузере.

                Минусы:
                    -Серверу требуется дополнительная обработка для анализа сложных запросов и проверки параметров.
                    -Оптимизация производительности запросов GraphQL тоже может быть сложной задачей.
                    -Внутри компании легко предсказать варианты использования и отладить узкие места в производительности, но при 
                        работе с внешними разработчиками эти варианты использования становятся трудными для понимания и оптимизации.

                Когда использовать:
                    Когда вам нужна гибкость запросов и поддержка консистентности. 
                    Хорошо подходит для внутреннего использования компании и плохо для персонального блога из-за своей сложности.
            
        Когда дело доходит до выбора парадигмы API, не существует универсального решения. Каждая из парадигм API хорошо подходит для 
        определённых вариантов использования. Важно понимать, какое решение лучше всего подойдет вашим клиентам, поможет вам достичь 
        бизнес-целей с учетом ограничений, с которыми вы работаете.





    RESTful vs REST
        REST — это только концепция, набор правил. Если же применять эти правила к приложению, то уже говорят о RESTFul. 
        Требования вы можете увидеть на википедии, чем больше требований вы выполните, тем более "full" получится приложение. 
        В теории при выполнении всех требований вы получайте RESTful приложение, если соблюдайте часть из них это REST-like.
        Это не протокол и не стандарт, никаких 100% объяснений тут нет, поэтому не стоит так сильно заморачиваться в его понимании, 
        очень часто REST употребляют совсем не по его значению. 




    GRPC
        gRPC — это высокопроизводительный фреймворк разработанный компанией Google для вызов удаленных процедур (RPC), работает поверх HTTP/2.

        gRPC – это протокол, обеспечивающий коммуникацию между различными конечными точками в распределенной системе. 
        Он использует HTTP/2 и буферы протоколов (protobuf). Как и любая система вызовов удаленных процедур, gRPC состоит из сервера, 
        определяющего методы и отклики, которые может вызывать клиент.

        gRPC может использовать protobuf в качестве языка для определения интерфейсов и в качестве формата для обмена передаваемыми сообщениями. 

        "Буферы протоколов – это разработанный Google расширяемый механизм, не зависящий от языка и платформы и предназначенный для сериализации структурированных данных"
        
        gRPC простой в использовании, отлично подходит для создания распределенных систем (микросервисов) и API. 
        Имеет встроенную поддержку для балансировки нагрузки, трассировки, аутентификации и проверки жизнеспособности сервисов. 
        Есть возможность создавать клиентские библиотеки для работы с бэкендом на 10 языках. Высокая производительность достигается 
        за счет использования протокола HTTP/2 и Protocol Buffers.

        protobuf — механизм, придуманный Google для сериализации структур данных. 
        Protobuf - формат сериализации используемый по умолчанию для передачи данных между клиентом и сервером. 
        Используя строгую типизацию полей и бинарный формат для передачи структурированных данных потребляет меньше ресурсов. 
        Время выполнения процесса сериализации/десериализации значительно меньше как и размер сообщений в отличии от JSON/XML.

        Для написания protobuf файлов используют язык описания интерфейсов (IDL). Например, чтобы описать структуру данных сообщения, 
        нужно добавить message, имя структуры, а внутри тип, название и номер поля. Номера полей очень важны для обратной совместимости, 
        поэтому не стоит менять их последовательность при добавлении или удалении полей. Старые номера можно резервировать. Пример profile.proto

        message Profile {
            reserved 3; // Резервируем поле под номером 3
            int32 id = 1;
            string name = 2;
            int32 age = 4;
            string email = 5;  enum PhoneType {
                MOBILE = 0;  // Поле 0 является значением по умолчанию
                HOME = 1;
                WORK = 2;
            }  message PhoneNumber {
                string number = 1;
                PhoneType type = 2;
            }
            
            repeated PhoneNumber phones = 6;
        }


        Типы RPC
            -Унарный (Unary RPC). Синхронный запрос клиента, который блокируются пока не будет получен ответ от сервера.
            -Серверный стрим (Server streaming RPC), при подключении клиента сервер открывает стрим и начинает отправлять сообщения.
            -Клиентский стрим (Client streaming RPC). То же самое, что и серверный, только клиент начинает стримить сообщения на сервер.
            -Двунаправленный стрим (Bidirectional streaming). Клиент инициализирует соединение, создаются два стрима. Сервер может отправить изначальные 
                данные при подключении или отвечать на каждый запрос клиента по типу “пинг-понга”.


    Что такое SSL/TLS-рукопожатие?
        SSL handshake – это общение сервера и клиента между собой, где каждый хочет достичь одной и той же цели – безопасно общаться с помощью симметричного шифрования. 
        При таком шифровании у двух сторон один ключ для шифрования и дешифрования сообщений. Такой ключ называется общим секретным – у всех пользователей, 
        которые обмениваются данными, один и тот же ключ.

        1 клиент здоровается и предоставляет шифры
        2 сервер шлет клиенту ssl-сертификат
        3 клиент проверяет информацию о ssl-сертификате
        4 с помощью открытого ключа герерируется общий секретный ключ
        5 сервер проверяет сертификат клиента
        6 общий секретный ключ расшифровывается с помощью секретного ключа
        7 теперь работает главный секрет
        8 главный секрет используется для шифрования и расшифрования информации



    Escape - анализ
        Каждая переменная, константы хранятся в каком-то месте физической памяти. 
        Доступ к этим ячейкам памяти осуществляется с помощью указателей.
        
        На физическом уровне стек и куча - это хранилиза памяти, расположенные в ОЗУ, которые имеют разные принципы работы.

        при работе программного обеспечения обычно используются две основные памяти:
            Стек - это блок памяти, выделенный для каждой функции. Память рассчитывается на время компиляции.
                -локальные переменные, аргументы функций, адреса возврата и т.д.
                -фиксированный размер
                -не поддерживает динамическое выделение памяти
                -просто очищается

            Куча - это блок памяти, который требуется вашему программному обеспечению во время выполнения. Куча — это вторая область памяти, 
                   помимо стека, используемая для хранения значений. Куча не самоочищается, как стеки, поэтому использование этой памяти обходится 
                   дороже. Прежде всего, затраты связаны со сборщиком мусора (GC), который должен содержать эту область в чистоте. Когда GC запускается, 
                   он будет использовать 25% доступной мощности вашего процессора. 
                    -глобальные переменные, ссылочный тип
                    -размер ограничен физическими характеристиками ОЗУ
                    -динамическое выделение памяти
                    -сложности в очистке

            Тогда почему стек такой быстрый? Есть две основные причины:
                -Нет необходимости в сборщике мусора для стека. Переменная помещается в стек после создания, а затем извлекается после возврата
                из функции.
                -Стек принадлежит одной горутине, поэтому хранение переменной в стеке не нужно синхронизировать в отличие от хранения в куче, 
                что также повышает производительность.


        Escape-анализ: он проверяет память, действительно ли она должна быть выделена в куче или может управляться внутри самого стека. 

        Escape analysis — это процесс, который компилятор использует для определения размещения значений, созданных вашей программой. 
        В частности, компилятор выполняет статический анализ кода, чтобы определить, может ли значение быть помещено в стековый фрейм для 
        функции, которая его строит, или значение должно «сбежать» в кучу. В Go нет ни одного ключевого слова или функции, которую вы могли 
        бы использовать, чтобы указать компилятору какое решение ему принять. Только то, как вы пишете свой код, условно позволяет повлиять 
        на это решение.

            Команда для escape-анализа:
                go build -gcflags="-m"

        Среда выполнения Go решает, какая переменная помещается в стек, а какая - в область памяти кучи. 
            Анализ стека:
                func main() {
                    fmt.Println("Called stackAnalysis", stackAnalysis())
                }
                
                //go:noinline
                func stackAnalysis() int {
                    data := 55
                    return data                                     // возвращается int. Находится в стеке функции stackAnalysis()
                }

                > go build -gcflags="-m"
                >    "Called stackAnalysis" escapes to heap          // Called stackAnalysis, который является строковым литералом, уходит в кучу. 
                >    stackAnalysis() escapes to heap                 // 
                >    main ... argument does not escape

                Функции main и stackAnalysis размещены в стеке. 
                Поскольку функция имеет свои собственные переменные, они также размещаются где-то в стеке. 
                И когда функция возвращает, все переменные, связанные с этой функцией, также удаляются из памяти. 
                Таким образом, компилятор освобождается от своей работы, называемой сборкой мусора. 

            Анализ кучи:
                func main() {
                    fmt.Println("Called heapAnalysis", heapAnalysis()
                }

                //go:noinline
                func heapAnalysis() *int {
                    data := 55
                    return &data                                    // возвращается *int. Находится в куче
                }

                > go build -gcflags="-m"
                > &data escapes to heap                         // Таким образом, переменные глобального доступа должны быть перемещены в кучу
                > moved to heap: data
                > "Called stackAnalysis" escapes to heap          // Called stackAnalysis, который является строковым литералом, уходит в кучу. 
                >  stackAnalysis() escapes to heap                 // 
                >  main ... argument does not escape





    












Go. Подготовка к интервью
Какие темы стоит повторить


Мы собеседуем специалистов с разным бэкграундом и опытом в языках программирования. Поэтому для нас в первую очередь важна базовая подготовка и знания.
🔹 Go


Вопросы о языке обычно делятся на группы: теоретические и практические.

Первой группой мы проверяем знания того, какие возможности предоставляет язык, как устроены те или иные части runtime.

Вторая группа — это варианты решения задач в различных ситуациях. Например, когда лучше использовать mutex’ы или каналы, как понять, почему приложение использует так много памяти, и т. д.

Этот блок также обязательно включает одну или несколько задач на написание кода в онлайне.

🔹 Архитектура


Ozon — большая система, состоящая из тысяч различных компонентов. Инженерам приходится каждый день сталкиваться с построением решений, которые должны легко масштабироваться и быть отказоустойчивыми. Здесь мы можем предложить задачи на проектирование из реальной жизни.

🔹 Алгоритмы*


Мы ожидаем, что вы знакомы со стандартными алгоритмами, включая разные методы сортировки и обхода графов. Нужно уметь давать оценку сложности алгоритма в нотации big O.

🔹 Базы данных*


Множество сервисов используют и реляционные, и нереляционные базы данных, поэтому важно понимать их различия и сценарии использования, проектирование схем БД, основы оптимизации под высокие нагрузки (репликация/шардинг).

🔹 ОС и сети*


Мы ожидаем, что инженеры имеют представления:

    о работе в терминале;

    о сетевом стеке linux;

    о базовом troubleshooting’e: чем заняты ресурсы, просмотр логов и т. д.


* Для некоторых департаментов Ozon
📚 Полезные ресурсы для подготовки

    https://dave.cheney.net/practical-go/presentations/qcon-china.html

    https://tour.golang.org

    https://golang.org/doc/effective_go

    https://microservices.io/patterns/microservices.html  

    https://www.postgresql.org/docs/13/index.html 

    Вернон Вон «Предметно-ориентированное проектирование. Самое основное» 

    Нархид Ния, Гвен Шапира «Apache Kafka. Потоковая обработка и анализ данных»

    Ганс-Юрген Шениг «PostgreSQL 11. Мастерство разработки»

    Задачи на ресурсе https://leetcode.com уровня easy и middle