By Slerm


- Day 1 (Философия мониторинга) -

Задача мониторинга - ответить на ключевой вопрос: "Что происходит?"
Цель мониторинга - понять, что происходит в системе и получить обратную связь от системы на действия пользователей,
разработчиков, инфраструктуры и тд

Типы мониторинга
- по уровням (бизнес, сервис, инфраструктура)
- по задачам (пороговый, оперативный - состояние системы за последние 20 мин, ретроспективный - как система себя вела месяц/год назад)
- по целям (бизнес, финансовый, маркетинг, продуктовый)

OBSERVABILITY (metrics, logs, traces) --> alerting

Существуют различные методологии сбора метрик, которые следует выбирать в зависимости от сервиса/компонента:
- USE
    - Utilization — % полезной работы сервиса - время или процент использования ресурса, занятого «полезной работой»;
    - Saturation — перегруженность (насыщенность), то есть количество отложенной или поставленной в очередь «работы»;
    - Errors — количество ошибок в работе компонента.

- RED
    - Rate — количество запросов в единицу времени (например, rps на микросервис или сервер);
    - Errors — количество ошибок;
    - Duration (оно же latency) — время обработки одного запроса.

- LTES
    - Latency — время на обработку одного запроса (с разделением на успешные и ошибочные запросы);
    - Traffic — количество запросов к компоненту (для веб-сервера это могут http-запросы, для базы данных — транзакции и т.п.);
    - Errors — количество ошибок;
    - Saturation — здесь это количественная метрика, отражающая, насколько компонент использует свои ресурсы и сколько у него «работы в очереди».

Для веб- или application-сервера лучше подходят RED и LTES, для шины данных или обработчиков очередей задач — USE.

Модели сбора метрик:
- Pull (за метриками ходит, например, promehteus)
- Push (сервисы сами отправляют метрики)

Инструменты сбора:
- Prometheus-stack
- Zabbix
- Datadog
- и др

Логи. Типы логов:
- неструктурированные [INFO] <datetime> <message>
- полуструктурированные [INFO]<datetime> {json}
- структурированные {json}

Логи. Нужно решить:
- горячее/холодное хранение логов
- фиксированная/свободная структура
- генерация метрик/прямые запросы к логам

Логи. Инструменты:
- ELK/EFk
- Loki/Protmail
- и др

Трейсы. Структура:
- трейсы (слепок прохождения запроса от сервиса А к Б)
- сегменты (span)
- подсегменты
Трейсы состоят из аннотаций (indexed) и метаданных (non-indexed)

Полезности трейсов: 
- сэмплирование 
- Service Mesh
- генерация метрик из трейсов
- выявление аномалий

Трейсинг инструменты:
- Jaeger
- Zipkin
- и др

Алертинг - самое важное в обзервабилити:
- SLI (service level indicators) - набор ключевых метрик, по которым можно определить жизненный статус сервиса, 
его производительность, «удовлетворенность» конечных пользователей работой сервиса. Например, в SLI может входить 
количество 500-х ошибок или количество активных пользователей.
- SLA (Service level agreement) - так называемое «соглашение об уровне доступности сервиса», которое определяется 
как ВНЕШНЕЕ обязательство перед конечным пользователем или клиентом. Например, SLA нашей круглосуточной техподдержки 
обычно составляет 15 минут — за это время мы обязуемся отреагировать на запрос или инцидент клиента, и это не зависит 
от внутренних обстоятельств.
- SLO (Service level objective) - набор целевых, «желаемых» значений SLI, выход за пределы которых может привести к 
нарушению SLA конкретного сервиса или компонента. Максимально допустимое отклонение от «идеальных» показателей в 
данной концепции называется Error Budget (право на ошибку). Как пример, это может быть: максимальное количество 
500-х ошибок за 5 минут, максимальное время недоступности веб-страницы, максимально допустимая нагрузка на 
процессор и т д. Правильно алерт вешать на SLO

SLI->SLO->SLA

Типы алертов:
- пороговые
- трендовые

Уровни мониторинга
- бизнес-логика
- приложение
- os
- runtime
- железо
- сеть/данные
- VM/контейнеры
- виртуализация

Хелсчеки (обратить внимание):
- код и размер ответа
- "цепочный ребут" по вине liveness-пробы (куб отстреливает инстансы приложения из-за того, что одна реплика начала захлебываться от 
нагрузки (liveness probe = false), соответственно траффик шел на другие реплики (load balancing), перегружая их)
- health-чек не должен нагрузить систему

Утилизация ресурсов CPU/RAM (приложение и хост-машина):
- min
- max
- average

Количество реплик приложения/инстансов ВМ:
- оптимизация schedule
- оптимизацияконфигурации nodes
- прогнозирование нагрузки
- детект аномалий !!! (увеличилось количество нод в кластере, 500-ые ошибки как следствие. 
Что произошло: приложение не влазило по ОЗУ на ноду, но хотело задеплоиться одной репликой)

Коммуниации между приложениями
- внутренние внешние коммуникации (необходимо мониторить их доступность)
- синхронное / асинхронное взаимодействие (шина данных, например)

Пример: 
- мониторим сервис А и Б
- мониторим Queue Broker
но еще нужно дописать тест - когда в сервисе А отправили через брокера данные в Б и они должны прийти в Б!!!!

Мониторинг как часть CI/CD-процесса
- количество успешных неуспешных выкладок
- длительность сборки/выкладки
- количество пройденных/заваленных тестов
- организация доставки метрик, мониторинга (scrape-конфиги, ServiceMonitors)
- алерты в пайплайне
- security-мониторинг (уязвимости, сканирование портов, докер-реджистри сканируется на уязвимости) 
- обязательный контроль "от перемены мест слагаемых сумма не меняется" - алерт на количество сервисов (мониторятся ли новые сервисы?)

Мониторинг приложения
- метрики приложения (метрики логики приложения, бизнес-метрики - количество успешных заказов, ARPU - сколько выручки приносит средний активный пользователь)
- мониторинг ошибок !!!
- генерация метрик на основе логов
- генерация метрик на основе трейсинга
- APM (application performance monitoring) - вплоть до вызова системных функций, кол-во горутин, может где-то индекс в бд не проставили

Сколько алертов нужно высылать? 
Важно: усталость от алертов ведет к пропущенным или игнорируемым уведомлениями, снижению времени реакции и выгоранию. 
Дежурные привыкают к тому, что алерты незначительны

Severity (Важность/приоритет)
- Critical/disaster - надо все бросить и реагировать немедленно (канал связи - звонок, telegram)
- High - реагировать нужно, но не вотпрямщаз, а в течение рабочего дня ("рабочие" каналы связи с проверкой выполнения - тикет)
- Medium/warning/info - все остальное (канал связи - почта)

Организация труда:
- получил алерт
- уведомил клиента 
Нужно не чинить, а информировать ответственных (SLA) - гораздо эффективнее увдомить ответственных (например соседнюю команду, 
которая сломала зависимый от вашего продукта сервис), нежели пытаться разобраться самому
- желательно иметь инструкции на случай инцидентов (с контактами того, кто знает как разобраться)
- не копить алерты, а разбирать их


Выводы
Мониторинг - полноценный программный продукт (должен разрабатываться параллельно разработке). Должны заниматься мониторингом DEV, OPS, DevOps, бизнес
Ключевые метрики - бизнесовые.
Если на алерт не отреагировали и ничего не сломалось - понижаем критичность
Если на алерт не отреагировали и все сломалось - повышаем
Если реакцию можно автоматизировать - автоматизируйте и уберите алерт



Литература
1 "Мониторинг начинается с метрик, или Как не сделать из алертов белый шум" - https://habr.com/ru/company/itsumma/blog/596845/
2 What is incident management? - https://www.atlassian.com/incident-management
