OPTIMIZATION

Утечки памяти (memory leaks)
    Утечки памяти (или давление памяти) могут принимать разные формы. Причина 
    возникновения утечек может крыться как в неверной реализации, так и в некорректном 
    проектировании системы.

    Важно выстроить систему, которая позволит сначала написать простой рабочий, но 
    неоптимизированный код, а уже затем улучшить производительность. Вот некоторые 
    распространённые примеры возникновения проблем с памятью:

        слишком большое количество выделений памяти, неверное представление данных
        интенсивное использование рефлексии или строк
        использование глобальных переменных
        «осиротевшие», бесконечные горутины

Утечки памяти (или давление памяти) могут принимать разные формы. Причина возникновения утечек может крыться как в неверной реализации, 
так и в некорректном проектировании системы.

Важно выстроить систему, которая позволит сначала написать простой рабочий, но неоптимизированный код, а уже затем улучшить производительность. 
Вот некоторые распространённые примеры возникновения проблем с памятью:
    слишком большое количество выделений памяти, неверное представление данных
    интенсивное использование рефлексии или строк
    использование глобальных переменных
    «осиротевшие», бесконечные горутины



// PPROF - Профилирование
    Go имеет несколько встроенных профилей, которые можно использовать в обычных случаях:
        goroutine — следы всех текущих горутин;
        heap — выборка выделений памяти живых объектов;
        allocs — выборка всех прошлых выделений памяти;
        threadcreate — следы стека, которые привели к созданию новых потоков в операционной системе;
        block — следы стека, которые привели к блокировке примитивов синхронизации;
        mutex — следы стека держателей конфликтующих мьютексов.
    
    Heap (куча) — это абстрактное представление места, где операционная система хранит объекты, которые использует код. 
    Впоследствии эта память очищается сборщиком мусора или освобождается вручную в языках программирования без сборки мусора.

    Куча — не единственное место, где происходит выделение памяти. Часть также выделяется на стеке. Его цель — быстрый доступ к памяти. 
    В Go стек обычно используется для присвоений, которые происходят в рамках функции. Другой момент, где Go использует стек, — когда 
    компилятор «знает», сколько памяти необходимо зарезервировать перед выполнением (например для массивов фиксированного размера).

    Данные кучи должны быть освобождены с использованием сборки мусора, в то время как данные стека — нет. Поэтому гораздо эффективнее 
    использовать стек там, где это возможно.

    Профайлер CPU по умолчанию работает в течение 30 секунд. Он использует выборку, чтобы определить, какие функции тратят большую часть 
    процессорного времени. Рантайм Go останавливает выполнение каждые десять миллисекунд и записывает текущий стек вызовов всех работающих горутин.

    Тогда почему стек такой быстрый? Есть две основные причины:
        -Нет необходимости в сборщике мусора для стека. Переменная помещается в стек после создания, а затем извлекается после возврата 
        из функции.
        -Стек принадлежит одной горутине, поэтому хранение переменной в стеке не нужно синхронизировать в отличие от хранения в куче, что 
        также повышает производительность.

    Автоматическое управление памятью – вещь удобная, но в мире, увы, нет ничего бесплатного. Выделение памяти на куче не только значительно медленнее, 
    чем выделение на стеке, но ещё и косвенно влияет на производительность. Каждый фрагмент памяти, который вы выделяете в куче, добавляет работы 
    сборщику мусора и заставляет использовать больше ресурсов процессора. Единственный способ заставить приложение тратить меньше времени на сборку 
    мусора – сократить количество аллокаций.


    Запуск профилировщика
        go tool pprof <исполняемый_файл> <профайл>
    
    Когда профилирование ЦП включено, программа Go останавливается примерно 100 раз в секунду и записывает выборку, состоящую из счетчиков программ 
    на выполняющемся в данный момент стеке горутины:
        (pprof) top10
            Total: 2525 samples           
                298  11.8%  11.8%      345  13.7% runtime.mapaccess1_fast64
                268  10.6%  22.4%     2124  84.1% main.FindLoops
                251   9.9%  32.4%      451  17.9% scanblock
                178   7.0%  39.4%      351  13.9% hash_insert
                131   5.2%  44.6%      158   6.3% sweepspan
                119   4.7%  49.3%      350  13.9% main.DFS
                96   3.8%  53.1%       98   3.9% flushptrbuf
                95   3.8%  56.9%       95   3.8% runtime.aeshash64
                95   3.8%  60.6%      101   4.0% runtime.settype_flush
                88   3.5%  64.1%      988  39.1% runtime.mallocgc
    В профиле 2525 образцов, поэтому он работал чуть более 25 секунд.
    1 образец (sample) = 1 сохранение содержимого стека
    Третий столбец показывает промежуточный итог во время листинга: на первые три строки приходится 32,4% выборок. 
    Четвертый и пятый столбцы показывают количество выборок, в которых появилась функция. (либо работающий, либо 
    ожидающий возврата вызванной функции)

    Пример:
        Функция runtime.mapaccess1_fast64 работала в течение 298 выборок (11.8%)
        

    (pprof) web - записывает график данных профиля в формате SVG и открывает его в веб-браузере.
    (pprof) web <funcNameRegExp> - использовать только образцы, которые включают определенную функцию
    (pprof) list <funcNameRegExp> - показать листинг функции с замерами по затратам ресурсов
    (pprof) weblist <funcNameRegExp> - показать листинг функции с замерами по затратам ресурсов в браузере
    (pprof) nodefraction=0.1 - игнорировать узлы, которые не составляют по крайней мере 10% всех образцов
    (pprof) alloc_space - переключиться в режим аллокаций памяти

    go tool pprof http://localhost:6060/debug/pprof/profile   # 30-second CPU profile
    go tool pprof http://localhost:6060/debug/pprof/heap      # heap profile
    go tool pprof http://localhost:6060/debug/pprof/block     # goroutine blocking profile




Несколько способов начать работу с профилированием:
    1) С помощью тестов и тестов, используя флаги -cpu profile и -memprofile.
    Создайте профиль для бенчмарка: go test . -bench . -cpu profile prof.cpu
    Затем проанализируйте профиль: перейдите к инструменту pprof [binary] prof.cpu

    2) импортируйте "_ net/http/pprof" для добавления "/debug/pprof" эндпоинта в свой сервис.
    Запустите профиль и проанализируйте результаты напрямую:
    перейти к инструменту "pprof -seconds 5 http://localhost:9090/debug/pprof/profile"

    3) Запустите профиль из кода, вызвав runtime.StartCPUProfile or runtime.WriteHeapProfile.
    Эти профили анализируются с помощью инструмента go pprof

    top10: показать 10 топ функций по затраченным ресурсам только на эту функцию
    top10 -cum: показать 10 топ функций по затраченным ресурсам только на эту функцию + затраченные ресурсы на вызовы функций из этих функций
    list regex: для отображения кода функций, соответствующих регулярному выражению
    disasm regex: для отображения разборки функций, соответствующих регулярному выражению 


    go test -bench . -benchmem -cpuprofile prof.cpu -memprofile prof.mem
    go tool pprof stats.test prof.cpu
    go tool pprof -alloc_objects stats.test prof.mem
    
    go build -gcflags=-m . - При этом выводится такая информация, как встроенные функции, “утечки” и “escapes” (например, переменные, выделенные в куче).
        






// Получение данных кучи с помощью pprof

// Использование pprof
    Есть две основные стратегии анализа памяти с помощью pprof. Одна из них называется inuse и заключается в рассмотрении 
    текущих выделений памяти (байтов или количества объектов). Другая носит название alloc и заключается в просматривании 
    всех выделенных байтов или количества объектов во время выполнения программы.

    Есть два основных способа полученить данные. Первый обычно используют в качестве части теста, и он включает импорт runtime/pprof
    и затем вызов pprof.WriteHeapProfile(some_file) для записи информации в кучу.

        // Функция lookup() берёт профиль
        namepprof.Lookup("heap").WriteTo(some_file, 0)

    WriteHeapProfile() существует для обратной совместимости. Остальные профили не имеют таких возможностей, и вы должны использовать 
    функцию Lookup(), чтобы получить данные профилей.

    Второй, более интересный способ — пустить его через HTTP (по веб-адресу). Это позволит извлекать конкретные данные из запущенного 
    контейнера в тестовой или e2e-среде или даже из продакшна.


    Профилирование
    Профилирование – это важная часть разработки и поддержки приложения. С его помощью
    можно найти узкие места, которые нагружают ЦПУ и оперативную память.

    Запуск бенчмарка (снятие профиля): 
        go test -bench . -benchmem -cpuprofile=cpu.out -memprofile=mem.out -memprofilerate=1 main.go 
    Анализ профиля (CPU):
        go tool pprof main.test.exe cpu.out
        (pprof) top  - топ выполняемых операций
            ...
        (pprof) list <func_name> - вывод затрат по времени для конкретных строк кода
        (pprof) web - вывод в браузере графа (дерева) выполнения последовательности команд
    Анализ профиля (Memory)
        go tool pprof main.test.exe mem.out
        (pprof) alloc_space - выделение памяти
        (pprof) top
        (pprof) list
        (pprof) web
        (pprof) alloc_objects
        (pprof) list <func_name> - вывод затрат по времени для конкретных строк кода

    В golang существует утилита go tool pprof, которая вместе с пакетом 
    "net/http/pprof" позволяет увидеть общую картину выполнения приложения.
    Встраивание профилировщика в приложение производится с помощью пакета 
    "net/http/pprof", который предоставляет набор профилей для анализа в виде 
    http-обработчиков (handler):

    import "net/http/pprof"

    <...>
        r := chi.NewRouter()
        r.Mount("/debug", Profiler())
    <...>

    func Profiler() http.Handler {
        r := chi.NewRouter()

        r.Get("/", func(w http.ResponseWriter, r *http.Request) {
        http.Redirect(w, r, r.RequestURI+"/pprof/", http.StatusMovedPermanently)
        })
        r.HandleFunc("/pprof", func(w http.ResponseWriter, r *http.Request) {
        http.Redirect(w, r, r.RequestURI+"/", http.StatusMovedPermanently)
        })

        // Получение списка всех профилей
        r.HandleFunc("/pprof/*", pprof.Index)
        // Отображение строки запуска (например: /go-observability-course/examples/caching/redis/__debug_bin)
        r.HandleFunc("/pprof/cmdline", pprof.Cmdline)
        // профиль ЦПУ, в query-параметрах можно указать seconds со значением времени в секундах для снимка (по-умолчанию 30с)
        r.HandleFunc("/pprof/profile", pprof.Profile)
        r.HandleFunc("/pprof/symbol", pprof.Symbol)
        // профиль для получения трассировки (последовательности инструкций) выполнения приложения за время seconds из query-параметров ( по-умолчанию 1с)
        r.HandleFunc("/pprof/trace", pprof.Trace)

        <...>

        return r
    }

    Запуск профиля ЦПУ
        Перед запуском go tool pprof нужно нагрузить программу.
        Сразу после предыдущей команды запускаем go tool pprof:

        go tool pprof http://localhost:9000/debug/pprof/profile\?seconds\=5
        Fetching profile over HTTP from http://localhost:9000/debug/pprof/profile?seconds=5
        Saved profile in /Users/nshibalov/pprof/pprof.samples.cpu.011.pb.gz
        Type: cpu
        Time: Aug 21, 2021 at 8:54pm (MSK)
        Duration: 5.20s, Total samples = 8.74s (168.15%)
        Entering interactive mode (type "help" for commands, "o" for options)
        (pprof)  

        В открывшемся приложении есть консоль. Для того чтобы увидеть граф вызовов, 
        надо выполнить команду web, после чего откроется браузер с графом:

        (pprof) web

        На данном графе видно название функций и время затраченное в них. Чтобы получить
        более детальную информацию, можно выполнить команду weblist с именем функции,
        например:

        (pprof) weblist GetUserArticles
        (pprof) 

        Ещё одна очень полезная команда top -cum. Она показывает функции, отсортированные
        по максимальному времени использования ЦПУ
    
    Запуск профиля аллокаций памяти
        go tool pprof http://localhost:9000/debug/pprof/heap
        Fetching profile over HTTP from http://localhost:9000/debug/pprof/heap
        Saved profile in /Users/nshibalov/pprof/pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.003.pb.gz
        Type: inuse_space
        Time: Aug 21, 2021 at 9:29pm (MSK)
        Entering interactive mode (type "help" for commands, "o" for options)
        (pprof) web




    

    // Практика 
        Профилирование, источник - эндпоинт
        go tool pprof http://localhost:8080/debug/pprof/allocs

        web
        list
        weblist <funcNameRegExp>
        // top (объяснение https://stackoverflow.com/questions/32571396/pprof-and-golang-how-to-interpret-a-results)
            (pprof) top
            Showing nodes accounting for 9109.21MB, 99.46% of 9158.22MB total
            Dropped 27 nodes (cum <= 45.79MB)
            Showing top 10 nodes out of 21
                flat  flat%   sum%        cum   cum%
            2074.67MB 22.65% 22.65%  2074.67MB 22.65%  github.com/eskriett/spell.(*dictionaryDeletes).add
            1813.94MB 19.81% 42.46%  3097.46MB 33.82%  github.com/eskriett/spell.(*Spell).generateDeletes

            flat - количество ресурсов (времени, памяти), затраченного на непосредственное выполнение команд функции (прямые
                операции) без учета количества ресурсов вызываемых функций (т.е. только команды самой функции)
            cum - общее количество ресурсов функции = непосредственное выполнение команд функции (прямые операции) + 
                ресурсы функций, вызываемых внутри исследуемой.

                т.е.:
                    Assuming there is a function foo, which is composed of 3 functions and a direct operation.
                    func foo(){
                        a()                                 step1
                        b()                                 step2
                        do something directly.              step3
                        c()                                 step4
                    }

                    Imagine when you call function foo, it takes 6 seconds, and the time distribution are following.

                    func foo(){
                        a()                                 // step1 takes 1s
                        b()                                 // step2 takes 1s
                        do something directly.              // step3 takes 3s
                        c()                                 // step4 takes 1s
                    }

                        flat -  would be the time spent on step3.
                        cum  - would be the total execution time of foo, which contains sub-function call and direct operations. 
                        (cum = step1+ step2+ step3+ step4)
            
            sum% - означает, сколько времени/памяти было потрачено предыдущими строками. Sum% может помочь вам быстро определить большие камни. 

















// BENCHMARKS (бенчмарки)
    Бенчмарки желательно запускать несколько раз, чтобы убедиться в корректности результатов.
    
    Запуск: 
        go test -bench <file> -race=1
    
    Запуск бенчмарков 
        go test -bench . -cpuprofile path/to/.prof -benchtime 3s

    func Benchmark_FuncName(b *testing.B) {
        b.Skip()        // пропуск бенчмарка
        for i:=0; i<b.N; i++ {
            emulateLoad(...)        // функция нагрузки
        }
    }

        
    1) Важно начать название функции с Benchmark
    2) Бенчмарки выполняются последовательно и не влияют друг на друга

    Определим функции: 

        // Количество выполняемых горутин   
        func MutexCounter() int {
            goroutinesCount := 0
            wg := sync.WaitGroup{}
            m := sync.Mutex{}

            for i:=0; i<1000; i++ {
                wg.Add(1)
                go func() {
                    m.Lock()
                    goroutinesCount++
                    m.Unlock()

                    time.Sleep(time.Second)
                    
                    m.Lock()
                    goroutinesCount--
                    m.Unlock()
                }
            }

            wg.Wait()
            return goroutinesCount
        }

        // Количество выполняемых горутин на Atomic
        func AtomicCounter() int32 {
            goroutinesCount := int32(0)
            wg := syncWaitGroup{}

            for i:=0; i<1000; i++ {
                wg.Add(1)
                go func() {
                    atomic.AddInt32(&goroutinesCount, 1)
                    
                    time.Sleep(time.Second)
                    
                    atomic.AddInt32(&goroutinesCount, -1)
                }
            }

            wg.Wait()
            return goroutinesCount
        }


    Напишем бенчмарки:
        func BenchmarkMutexCounter(b *testing.B) {
            for i:=0; i < b.N; i++ {                        // b.N - не контроллируется нами
                _ = MutexCounter()                          
            }
        }

         func BenchmarkAtomicCounter(b *testing.B) {
            for i:=0; i < b.N; i++ {                        // b.N - не контроллируется нами
                _ = AtomicCounter()                          
            }
        }

        после запуска:
        BenchmarkAtomicCounter
        BenchmarkAtomicCounter-8        3279            3744946 ns/op                   // BenchmarkAtomicCounter-8 - 8=кол-во ядер в системе. 
                                                                                        // 3279 - количество операций за единицу времени
                                                                                        // в goBench есть некоторый временной интервал, который 
                                                                                        // одинаковый для двух функций выше
                                                                                        // 3744946 ns/op - количество наносекунд на одно выполнение функции
        BenchmarkMutexCounter
        BenchmarkMutexCounter-8         2205            528361 ns/op



    

// GO VET
    vet проверяет исходный код Go и сообщает о подозрительных конструкциях, таких как вызовы Printf, аргументы которых не совпадают 
    с форматом строки. vet использует эвристику, которая не гарантирует, что все отчеты являются подлинными проблемами, но он может 
    найти ошибки, не обнаруженные компиляторами.

    Vet обычно вызывается с помощью команды go. Эта команда проверяет пакет в текущем каталоге:
        go vet
        go vet ./app
        go vet ./config ./internal/*

    По умолчанию все аналайзеры vet включены:
        asmdecl      сообщить несоответствия между сборочными 
                    файлами (assembly files) и Go декларациями

        assign       проверить на бесполезные назначения

        atomic       проверить на общие ошибки 
                    используемые в sync/atomic пакете

        bools        проверить на общие ошибки 
                    затрагивающие булевы (boolean) операторы

        buildtag     проверить что +build теги 
                    правильно сформированы и корректно размещены

        cgocall      выявить некоторые из нарушений 
                    правил передачи cgo указателей
        .... и другие




ЛИНТЕРЫ
    // GOLINT
        golint - это линтер, поддерживаемый разработчиками Go. Он предназначен для обеспечения соблюдения соглашений о кодировании, 
        описанных в Effective Go и CodeReviewComments . Эти же соглашения используются в проекте Go с открытым исходным кодом и 
        в Google. golintзанимается только стилистическими вопросами, и его правила больше похожи на мнения, чем на жесткие стандарты.
        Как говорится в README проекта:

        Предложения, сделанные golint, именно таковы: предложения. Golint не идеален… не относитесь к его продукции как к золотому стандарту.

        golint— это лишь один из многих возможных линтеров Go , которые вы можете использовать. 
        Запуск из корня проекта:
            golint ./...


    // golangci-lint
        Он анализирует код только один раз, после чего выполняет анализ со всеми линтерами за меньшее время
        golangci-lint run ./...