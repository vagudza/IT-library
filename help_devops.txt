Docker - это программное обеспечение, которое начинало с того, что зародилось в одной компании, 
как внутренний проект platform-as-a-service в компании dotCloud.

    Docker наиболее часто используемый инструмент для написания Микросервисов. 
    Микросервисы - это архитектурный шаблон проектирования, который следует философии "разделения ответственности".

    docker: 
    основная задача запустить приложение.
    Контейнер работатет до тех пор, пока работает приложение


    Docker контейнеры создаются на основе docker images.
    Для создания собственных docker images необходимо:

        В dockerfile прописать, все необходимые команды на основе которых будет создавать image(образ).
        После чего ввести команду: docker build
        Для запуска контейнера на основе образа: docker run


    Ключевое преимущество Докера в том, что он позволяет пользователям упаковать приложение со всеми его зависимостями 
    в стандартизированный модуль для разработки. В отличие от виртуальных машин, контейнеры не создают такой дополнительной 
    нагрузки, поэтому с ними можно использовать систему и ресурсы более эффективно.



Терминология
    Images (образы) - Схемы нашего приложения, которые являются основой контейнеров.
    Containers (контейнеры) - Создаются на основе образа и запускают само приложение.
    Docker Daemon (демон Докера) - Фоновый сервис, запущенный на хост-машине, который отвечает за создание, 
        запуск и уничтожение Докер-контейнеров. Демон — это процесс, который запущен на операционной системе, с которой взаимодействует клиент.
    Docker Client (клиент Докера) - Утилита командной строки, которая позволяет пользователю взаимодействовать с демоном. 
    Docker Hub - Регистр Докер-образов. Грубо говоря, архив всех доступных образов.







Dockerfile
Одно из основных действий, выполняемых средствами Dockerfile — это установка пакетов.

# комментарий
FROM python:3.6                 # определяем образ, в котором должен быть питон с версией 3.6
                                # начинаем сборку с образа с питоном с нужной версией

RUN mkdir -p /usr/src/app/      # выполнение команды
    pip install --no-cache-dir -r requirements.txt          # установка зависимостей, указанных в txt файле (flask==1.1)
WORKDIR /usr/src/app/           # рабочая директория - все скрипты будут запущены отсюда

COPY . /usr/src/app/            # копирует содержимое из локальной машины с корня в указанную папку (COPY принимает 2 параметра откуда и куда копировать)

EXPOSE 8080                     # декларация проброски порта

ENV TZ Europe/Moscow            # указываем переменную окружения и ее значение (альтернатива-парметр -e в docker run)

CMD ["python", "app.py"]        # команда в консоли (выполняется в shell)



Дюжина инструкций Dockerfile

    FROM — задаёт базовый (родительский) образ.
    LABEL — описывает метаданные. Например — сведения о том, кто создал и поддерживает образ.
    ENV — устанавливает постоянные переменные среды.
    RUN <command> | ["executable", "param1", "param2"] — выполняет команду и создаёт слой образа. 
        Используется для установки в контейнер пакетов.
    COPY — копирует в контейнер файлы и папки.
    ADD — копирует файлы и папки в контейнер, может распаковывать локальные .tar-файлы.
    CMD — описывает команду с аргументами, которую нужно выполнить когда контейнер будет запущен. 
        Результаты выполнения этой команды не добавляются в образ во время его сборки. 
        Аргументы могут быть переопределены при запуске контейнера. (docker run pyramid php /cli.php 9   - [CMD php /cli.php] - оригинальная CMD команда, 
        записанная в Dockerfile php /cli.php - будет переопределена новой)
        В файле может присутствовать лишь одна инструкция CMD.
        Если пользователь указывает аргументы для docker runтогда они переопределят по умолчанию указано в CMD. 
    WORKDIR — задаёт рабочую директорию для следующей инструкции (аналогично mkdir /dir && cd /dir).
    ARG — задаёт переменные для передачи Docker во время сборки образа.
    ENTRYPOINT — предоставляет команду с аргументами для вызова во время выполнения контейнера. Аргументы не переопределяются.
        В таком случае, CMD будет добавлена к тому, что выполнится в ENTRYPOINT:
            FROM php:7.2-cli
            COPY cli.php /cli.php
            RUN chmod +x /cli.php
            ENTRYPOINT ["php", "/cli.php"]
            ## аргумент, который передаётся в командную строку
            CMD  ["9"]  # пользователь сможет переопределить этот аргумент, передавая его в командную строку, во время запуска контейнера.
                для этого пересоберем образ         docker build . --tag pyramid
                запустим контейнер с аргументом     docker run pyramid 3
    EXPOSE — указывает на необходимость открыть порт из контейнера во внешнюю ОС.
    VOLUME — создаёт точку монтирования для работы с постоянным хранилищем.
        Монтирование директории в Docker контейнер - это предоставление доступа контейнеру на чтение содержимого вашей папки из основной операционной системы.
        Для того, чтобы смонтировать папку из основной системы в контейнер, можно воспользоваться командой
            docker run -v <DIRECTORY>:<CONTAINER_DIRECTORY> ...
        Только путь к монтируемой папке должен быть прописан полностью
            docker run -it -v C:\projects\docker-example\cli:/mounted  ubuntu:18.10 /bin/bash
        Вместо того, чтобы каждый раз, при запуске контейнера, писать, какие из папок вы хотите смонтировать,
        вы просто можете создать один контейнер с общими данными, который потом будете прикреплять. 


еще пример dockerfile (для Go)

FROM golang:1.17.1-alpine as bulder
WORKDIR /build

COPY . /build/                                  # перенос всего содержимого репозитория (кроме того, что в .gitignore) в папку build
RUN CGO_ENABLED=0 GOOS=linux go build -a -o profile cmd/profile/main.go

# generate clean, final image for end users
FROM alpine:3.11.3
COPY --from=builder /build/profile .            # скопировали exe-шник, конфиги и папку templates
COPY --from=builder /build/configs/* /configs/
RUN mkdir -p Stemplates

# executable
ENTRYPOINT ["./profile"]








1 docker build -t <image_name> .                            # cоздание своего докер-образа: -t - tag, . - запуск из текущего каталога 
  docker build <DOCKERFILE_PATH> --tag <IMAGE_NAME>         # <DOCKERFILE_PATH> - путь к файлу Dockerfile (. - текущая директория),
                                                              <IMAGE_NAME> - имя, под которым образ будет создан


2 docker images                                             # список созданных образов 
3 docker run <image_name>                                   # преобразование образа в контейнер (запуск контейнера, имя контейнера будет определено автоматически)
                                                            # docker run находит образ, создает контейнер поверх него и запускает контейнер

docker run --name <container_name> <image_name>             # запуск контейнера с образа image_name (можно использовать чужие контейнеры:  
            -d      # запуск контейнера в фоне                                                      # если в образах нет mongo, то в можно прописать в <image_name> mongo (для временной БД)
            --rm    # удаление контейнера после завершение приложения
            -p <local_port>:<container_port>
            -e TZ=Europe/Moscow                             # установка переменной окружения
            -v <local_path_to_folder>:<path_in_container>   # монтируем локальную директорию в контейнер (абс. путь на хост машине:абс. путь внутри докер конт.)
            -v <volume_name>:<path_in_container>            # другой способ монтирования - использование volume

docker volume ls                                            # список всех директорий, монтируемых к контейнеру. Аналог (-v), только директория создается докером неизвестно где и монтируется в контейнер
docker volume create <volume_name>                          # создаем volume, неизвестно где (докер сам решает)

docker ps                                                   # выводит список запущенных контейнеров на вашей хост-машине.
        -a                                                  # показать список всех контейнеров, в т.ч. завершенных
docker ps -a -q                                             # вывести id всех контейнеров
docker rm <container_id | container_name>                   # удалить контейнер по имени/id
docker rm $(docker ps -qa)                                  # удалить все контейнеры
docker rmi <image_id | repository:tag>                      # удаление образа
docker rmi $(docker images -q)                              # удаление всех образов
docker stop <container_name>                                # остановка контейнера
docker push <image_name>                                    # загрузка образа                                                 








docker compose:
надстройка над docker
используется для одновременного управления несколькими контейнерами, входящими в состав приложения.
Docker Compose управляет контейнерами, запускает их вместе, в нужной последовательности, необходимой для вашего приложения.

docker-compose.yaml:
version: "3"                                # Файл docker-compose должен начинаться с тега версии (3 версия - самая последняя на даный момент).

volumes:                                    # список volumes
    mongodb_volume:

services:                                   # список микросервисов
    microservice1:                          # имя сервиса
        build: folder1/                     # шаги, описывающие процесс билдинга: сборка из папки folder1 (там лежит Dockerfile)
        restart: always                     # при перезагрузке виртуальной машины докер автоматически поднимет указанные контейнеры
        environment: 
            - TZ=Europe/Moscow
            - Param1=Value1
            - MONGO_DB_ADDR=mongodb         # для подключения к Монго
    
    mongodb:                                # к монге нет портов, но к ней могут подключиться микросервисы из этой сборки
        image: mongo:latest
        volumes:
            - mongodb_volume:/data/db
        restart: always

    microservice2:
        build:
            context: .                      # где находится Dockerfile, из которого будем билдить образ для контейнера.
        restart: always
        ports:                              # единственный порт для внешних подключений
            -8080:8080                      # [порт компьютера]:[порт контейнера] - для доступа извне к контейнеру
        command: python ./server.py         # Команда, которую нужно запустить после создания образа.
        network_mode: host                  # Описание типа сети - контейнер может обращаться к 'localhost' компьютера
        depends_on:                         # позволяет указывать, должен ли сервис, прежде чем запуститься, ждать, когда будут готовы к работе другие сервисы.
            - mongodb


docker-compose build                            # сборка проекта
docker compose up -d                            # запуск сервисов (-d в фоне)
docker compose down                             # остановить и удалить контейнеры и другие ресурсы, созданные командой docker-compose up
docker-compose logs -f [service name]           # журналы сервисов
docker-compose ps                               # список контейнеров
docker-compose exec [service name] [command]    # выполнить команду в выполняющемся контейнере
docker-compose images                           # вывести список образов



Инструкция по деплою:
Деплоймент - некоторое описание вашего микросервиса: что нужно сделать с вашим контейнером, когда он придет в кубернетес (как разворачивать, 
какие порты открывать). После деплоя запускается под. Для связки нескольких деплойментов нужно описать сервис. Кроме того, сервис можно создать,
чтобы прокинуть ваш деплоймент во внешнюю сеть (?). Теперь поды нужно связать (сеть)

1 Открываем в Gitlab ветку, из которой будем деплоить
2 Проверяем конфиг для микросервисов (порты). 
kubectl create ...
Для этого выполняем команду kubectl get svc - получаем список запущенных сервисов (?), их имена и порты - чтобы микросервисы друг друга видели
3 Проверяем gitlab-ci.yaml
4 Проверяем docker file
5 Делаем merge request develop-->main (поскольку в gitlab-ci.yaml прописан деплой из main)
6 Теперь в CI/CD-->pipelines появятся описанные в gitlab-ci.yaml стейджи (stages), в том числе build и deploy 
7 После прохождения стейджов все будет задеплоено

проверка деплоя: 
kubectl get pods


Новая инструкция по деплою:
1 Gitlab: закинуть рабочий код в develop
2 Gitlab: закинуть рабочий из develop в main, убрать галку "удалить сливаемую верку"
3 Gitlab: проверит возможность merge request. Нажать на кнопку Merge
4 Gitlab: запустится пайплайн, по результатам появятся поды. Проверяем kubectl get pod 
5 CMD: пробрасываем порты:
        kubectl port-forward auth-6cdff48c55-bqflk 8100:8100

для доступа к k8s бд Postgres необходимо перед подключением с клиента пробросить порты
kubectl port-forward --namespace team24 svc/postgresql 29000:5432
где 29000 - порт на локальной машине
5432 - порт в контейнере k8s








WSL (https://docs.microsoft.com/ru-ru/windows/wsl/tutorials/wsl-containers)

для работы с WSL в VS Code в терминале WSL нужно набрать "code ."
в терминале WSL команда "explorer.exe ." запускает проводник винды в текущей директории ubuntu

Вот несколько полезных команд DOCKER для получения сведений:

    Перечислить команды, доступные в интерфейсе командной строки Docker, можно, выполнив команду docker.
    Просмотреть сведения о конкретной команде можно, выполнив команду docker <COMMAND> --help.
    Перечислить образы Docker на вашем компьютере (сейчас только образ Hello-World) можно, используя следующие команды docker image ls --all.
    Перечислите контейнеры на компьютере с помощью: docker container ls --all или docker ps -a (без флага Показать все, будут отображаться только выполняющиеся контейнеры).
    Перечислите системную информацию об установке DOCKER, включая статистику и ресурсы (память ЦП & ), доступные в контексте WSL 2, с помощью: docker info

docker-machine ip default - ip адрес виртуальной машины, на коорой работает докер
docker-compose up - d - поднять указанные в docker-compose.yaml контейнеры. Запускать нужно эту команду из той же директории, где лежит docker-compose.yaml
docker-compose ps - посмотреть запущенные контейнеры
docker-compose logs -f kafka - вывод логов конейнера с именем kafka

пример запуска скрипта в контейнере докера:
docker exec \
    kafka_kafka_1 kafka-topics.sh \
    --create --topic quickstart-events --bootstrap-server :9092

docker exec -it producer_kafka_1 /bin/bash  - Команда exec позволяет выполнить команду внутри запущенного контейнера.
docker run -it ubuntu:18.10 /bin/bash       - Опция -it вместе с /bin/bash даёт доступ к выполнению команд в терминале внутри контейнера Ubuntu.
exit                                        #выйдет из контейнера, и вернётся в основную ОС (контейнер будет остановлен)



Создание собственного образа (на примере микросервиса Auth)

1 Установка зависимостей
    а) docker pull mongo
    б) 





 

CI/CD
    Общая концепция DevOps дала нам такие процессы, как непрерывная интеграция (CI) и непрерывная поставка (CD)
    Эти процессы обеспечивают активное тестирование и проверку правильности кода в ходе agile-разработки.

    CI - непрерывная интеграция (Builds+Tests)
        CI - фундаментальная рекомендация DevOps (и Agile), согласно которой разработчики регулярно проводят слияние изменений кода в центральном репозитории, 
        где выполняются автоматизированные сборки и тесты. При использовании непрерывной интеграции уделяется большое внимание автоматизации тестирования, 
        в результате которого при интеграции новых коммитов в основную ветку работа приложения не нарушается.
            что необходимо: 
                -необходимо написать автоматические тесты
                -необходим сервер для CI
                -слияние веток кода как можно чаще (раз в день минимум)
            профит:
                -меньше багов в рабочей среде
                -снижаются затраты на тестирование
            

    CD - может означать как непрерывную поставку (deploy to production - MANUAL), так и непрерывное развертывание (deploy to production - AUTOMATIC)
        Непрерывная поставка является продолжением непрерывной интеграции, поскольку при ней происходит автоматическое развертывание всех изменений кода в 
            тестовой и (или) рабочей среде после этапа сборки. Это значит, что автоматизирован не только процесс тестирования, но и процесс выпуска продукта, 
            поэтому приложение можно развернуть в любое время одним нажатием.
            Cледует выполнять развертывание в рабочей среде как можно раньше, обеспечивая выпуск небольших пакетов изменений, в которых легко найти ошибку в случае проблем.
                что необходимо:
                    -комплект тестов должен покрывать достаточное количество кода
                    -нобходимо настроить развертывание (для запуска вручную)
                профит:
                    -простое развертывание
                    -можно чаще выпускать релизы, ускоряя цикл обратной связи с клиентами
                    -уменьшение масштабов изменений (облегчение поиска багов и передачи знаний об изменениях коллегам)

        Непрерывное развертывание идет на один шаг дальше, чем непрерывная поставка. 
            При этом подходе каждое изменение, которое проходит все стадии производственного процесса, выпускается клиентам.
            Непрерывное развертывание — это отличный способ ускорить цикл обратной связи с клиентами и избавить команду от лишнего напряжения, потому что Дня релиза 
            больше не бывает.
                что необходимо:
                    -комплект тестов должен быть на самом высоком уровне, т.к. после тестирования приложение идет в релиз
                    -процесс документирования должен идти в ногу с темпами развертывания
                профит:
                    -ускорение процесса разработки
                    -облегчается выпуск фиксов в случае проблем
                    -клиенты выдят непрерывный поток улучшений, при этом качество повышается каждый день, а не раз в месяц




Пирамида тестирования (рекомендовано для запуска в CI)
    Начните с малого: реализуйте модульные тесты и постепенно работайте над увеличением покрытия кода.
    
    Пирамида тестирования (снизу ввверх):
        -Модульные тесты работают в узких областях и обычно проверяют поведение отдельных методов или функций 
            (являются быстрыми и незатратными в смысле реализации).
        -Интеграционные тесты проверяют, насколько правильно взаимодействуют несколько компонентов. Такие тесты могут 
            задействовать несколько классов или выполнять тестирование интеграции с другими сервисами.
        -Приемочные тесты похожи на интеграционные тесты, но они ориентированы на бизнес-сценарии, а не на сами компоненты.
        -Тесты пользовательского интерфейса обеспечивают, что приложение корректно функционирует с точки зрения пользователя.
            (сложными в реализации и медленными при выполнении, так как они часто требуют запуска полной среды, а также множества 
            сервисов для эмуляции поведения браузера или мобильного устройства)




DevSecOps
    обозначается цикл разработки программного обеспечения (SDLC) с непрерывной поставкой, в котором особое внимание уделяется безопасности.
    DevSecOps опирается на наработки и рекомендации общего подхода DevOps. Применение ценностей DevOps при обеспечении безопасности ПО означает,
    что проверка безопасности становится активной, неотъемлемой частью процесса разработки. 
    Согласно концепции DevSecOps, безопасность необходимо встраивать в продукт еще в процессе разработки, а не внедрять на этапе готового продукта.





k8s
    Каким бы замечательным ни был Kubernetes, есть вещи, которые он не может делать. Вещи как:
        -Мониторинг
        -Резервные копии дисков
        -Сканирование уязвимостей 

    а также 1000 других вариантов использования. Существуют различные способы расширения Kubernetes API:
        -Аннотации : добавление дополнительных произвольных пар ключ/значение к существующим объектам Kubernetes.
        -Пользовательские определения ресурсов : добавление новых свойств Kubernetes API. 


        Аннотации — это произвольные пары ключ/значение, которые добавляются к существующим определениям Kubernetes. 
        Одним из распространенных вариантов использования является обнаружение служб для базы данных временных рядов Prometheus. 
        



Термины:
    IaaS (Infrastructure-as-a-Service) — инфраструктура как услуга
    DRaaS (Disaster Recovery as a Service) — «аварийное восстановление как услуга» 
    BaaS (Backup as a Service) — «резервное копирование как услуга»


Какая технология лежит в основе IaaS
    Виртуализация - позволяет запускать несколько приложений или операционных систем на одном сервере. 
        В результате ресурсы оборудования распределяются более рационально. Такой подход сокращает время простоя
        железа, и IaaS-провайдер загружает его эффективнее. В результате клиент получает более выгодные условия 
        сотрудничества.

        Виртуальная машина (ВМ) - каждая операционная система, запущенная на одном физическом сервере
        Все они изолированы и не вмешиваются в работу друг друга. Эта изоляция позволяет большому числу 
        виртуальных машин безопасно работать на совместно используемом оборудовании.

        Каждая виртуальная машина получает свой набор вычислительных ресурсов: процессорные
        ядра, оперативную память, место на диске. В любой момент объем ресурсов можно
        увеличить или уменьшить.

        Виртуализация возможна благодаря работе гипервизора. Он занимается распределением памяти и процессорных 
        ядер, предоставляет виртуальным машинам вычислительные ресурсы и распределяет их в зависимости от нагрузки.
        Если виртуальной машине требуется больше места на диске, то она также получает необходимое
        пространство благодаря работе гипервизора.

        Одними из самых популярных гипервизоров сегодня являются решения VMware, Hyper-V, Xen и KVM. 
        Гипервизор позволяет IaaS-провайдеру увеличить доступность сервисов для клиентов (выше, чем указано 
        в SLA), повысить надежность ИТ-инфраструктуры и стабильность работы облака.

